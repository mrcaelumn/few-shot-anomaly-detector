{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbb1f7-1ac7-4293-8761-b388f2ef5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc299db8-c95f-470e-89ae-2f41a6cb6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "\n",
    "# Weight initializers for the Generator network\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "TRAIN = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "meta_step_size = 0.25\n",
    "\n",
    "inner_batch_size = 25\n",
    "eval_batch_size = 25\n",
    "\n",
    "meta_iters = 100\n",
    "eval_iters = 5\n",
    "inner_iters = 10\n",
    "\n",
    "eval_interval = 1\n",
    "train_shots = 25\n",
    "shots = 10\n",
    "classes = 1\n",
    "\n",
    "name_model = \"prototype_one_few_shot\"\n",
    "g_model_path = \"saved_model/g_\"+name_model+\"_\"+str(meta_iters)+\".h5\"\n",
    "d_model_path = \"saved_model/d_\"+name_model+\"_\"+str(meta_iters)+\".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828014f0-4825-4f9c-8e4e-c50bff9d4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for SSIM loss function\n",
    "class SSIMLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "         reduction=tf.keras.losses.Reduction.AUTO,\n",
    "         name='SSIMLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    def call(self, ori, recon):\n",
    "        recon = tf.convert_to_tensor(recon)\n",
    "        ori = tf.cast(ori, recon.dtype)\n",
    "\n",
    "        # Loss 3: SSIM Loss\n",
    "#         loss_ssim =  tf.reduce_mean(1 - tf.image.ssim(ori, recon, max_val=1.0)[0]) \n",
    "        loss_ssim = tf.reduce_mean(1 - tf.image.ssim(ori, recon, 2.0))\n",
    "        return loss_ssim\n",
    "    \n",
    "# class for Feature loss function\n",
    "class FeatureLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='FeatureLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, real, fake):\n",
    "        fake = tf.convert_to_tensor(fake)\n",
    "        real = tf.cast(real, fake.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        loss_feat = tf.reduce_mean(tf.pow((real-fake), 2))\n",
    "        return loss_feat\n",
    "    \n",
    "# class for Adversarial loss function\n",
    "class AdversarialLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='AdversarialLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, logits_in, labels_in):\n",
    "        labels_in = tf.convert_to_tensor(labels_in)\n",
    "        logits_in = tf.cast(logits_in, labels_in.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))\n",
    "\n",
    "# function for Generator Wassertein loss function\n",
    "def generator_wassertein_loss(fake_img):\n",
    "    fake = tf.convert_to_tensor(fake_img)\n",
    "    return -tf.reduce_mean(fake)\n",
    "\n",
    "# function for Discriminator Wassertein loss function\n",
    "def discriminator_wassertein_loss(real_img, fake_img):\n",
    "    fake = tf.convert_to_tensor(fake_img)\n",
    "    real = tf.cast(real_img, fake.dtype)\n",
    "    return tf.reduce_mean(fake) - tf.reduce_mean(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f0129-2529-4ace-bbef-848d8c4f8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate the auc value for lables and scores'''\n",
    "def roc(labels, scores, name_model):\n",
    "    \"\"\"Compute ROC curve and ROC area for each class\"\"\"\n",
    "    roc_auc = dict()\n",
    "    # True/False Positive Rates.\n",
    "    fpr, tpr, threshold = roc_curve(labels, scores)\n",
    "    # print(\"threshold: \", threshold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # get a threshod that perform very well.\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    # draw plot for ROC-Curve\n",
    "    # plot_roc_curve(fpr, tpr, name_model)\n",
    "    \n",
    "    return roc_auc, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c231433-0c03-4a84-a2b5-d40b36825ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delcare all loss function that we will use\n",
    "\n",
    "# for adversarial loss\n",
    "# cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "cross_entropy = AdversarialLoss()\n",
    "# L1 Loss\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "# L2 Loss\n",
    "mse = tf.keras.losses.MeanSquaredError() \n",
    "feat = FeatureLoss()\n",
    "\n",
    "# SSIM loss\n",
    "ssim = SSIMLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229876d-50de-4906-ba58-519932cfec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCAdam(tf.keras.optimizers.Adam):\n",
    "    def get_gradients(self, loss, params):\n",
    "        # We here just provide a modified get_gradients() function since we are\n",
    "        # trying to just compute the centralized gradients.\n",
    "\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= tf.reduce_mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47377645-0e75-4ee5-881c-99f25b96b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))\n",
    "    filename = f\"samples/generated_plot_epoch-{epoch}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa049b05-f27c-45be-949a-c362baa633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_result(iters, loss, name, model_name, colour):\n",
    "    plt.plot(epochs, loss, colour, label=name)\n",
    "#     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(model_name+ '_'+name+'_epoch_result.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80474f87-23e7-4760-9a05-1d76ca4d740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names):\n",
    "\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            if \".DS_Store\" != img:\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "\n",
    "                image_list.append(filpath)\n",
    "                label_list.append(class_num)\n",
    "\n",
    "    return image_list, label_list\n",
    "\n",
    "def prep_stage(x):\n",
    "    x = tf.image.resize(x, (IMG_H, IMG_W))\n",
    "    return x\n",
    "\n",
    "def extraction(image, label):\n",
    "    # This function will shrink the Omniglot images to the desired size,\n",
    "    # scale pixel values and convert the RGB image to grayscale\n",
    "    img = tf.io.read_file(image)\n",
    "    img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "    img = prep_stage(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    #     rescailing image from 0,255 to -1,1\n",
    "    img = (img - 127.5) / 127.5\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e680f9-04ec-4944-9f40-59936ec451cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_gen_disc(mode, g_model_inner, d_model_inner, g_filepath, d_filepath, test_data_path):\n",
    "    g_model_inner.load_weights(g_filepath)\n",
    "    d_model_inner.load_weights(d_filepath)\n",
    "#         path = \"mura_data/RGB/test_data/normal/normal.bmp\"\n",
    "#         path = \"mura_data/RGB/test_data/defect/defect.bmp\"\n",
    "#         path = \"rgb_serius_defect/BUTTERFLY (2).bmp\"\n",
    "    paths = {\n",
    "        \"normal\": test_data_path+\"/normal/normal.png\",\n",
    "        \"defect\": test_data_path+\"/defect/defect.png\",\n",
    "    }\n",
    "\n",
    "    for i, v in paths.items():\n",
    "        print(i,v)\n",
    "\n",
    "        width=IMG_W\n",
    "        height=IMG_H\n",
    "        rows = 1\n",
    "        cols = 3\n",
    "        axes=[]\n",
    "        fig = plt.figure()\n",
    "\n",
    "\n",
    "        img = tf.io.read_file(v)\n",
    "        img = tf.io.decode_png(img, channels=IMG_C)\n",
    "\n",
    "        name_subplot = mode+'_original_'+i\n",
    "        axes.append( fig.add_subplot(rows, cols, 1) )\n",
    "        axes[-1].set_title('_original_')  \n",
    "        plt.imshow(img.numpy().astype(\"int64\"), alpha=1.0)\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        img = tf.cast(img, tf.float64)\n",
    "        img = (img - 127.5) / 127.5\n",
    "\n",
    "\n",
    "        image = tf.reshape(img, (-1, IMG_H, IMG_W, IMG_C))\n",
    "        reconstructed_images = self.generator.predict(image)\n",
    "        reconstructed_images = tf.reshape(reconstructed_images, (IMG_H, IMG_W, IMG_C))\n",
    "#             reconstructed_images = reconstructed_images[0, :, :, 0] * 127.5 + 127.5\n",
    "#             reconstructed_images = reconstructed_images[0]\n",
    "        reconstructed_images = reconstructed_images * 127 + 127\n",
    "\n",
    "        name_subplot = mode+'_reconstructed_'+i\n",
    "        axes.append( fig.add_subplot(rows, cols, 3) )\n",
    "        axes[-1].set_title('_reconstructed_') \n",
    "        plt.imshow(reconstructed_images.numpy().astype(\"int64\"), alpha=1.0)\n",
    "        plt.axis('off')\n",
    "\n",
    "        fig.tight_layout()    \n",
    "        fig.savefig(mode+'_'+i+'.png')\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241a868-2a33-42de-b550-605c148710c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # This class will facilitate the creation of a few-shot dataset\n",
    "    # from the Omniglot dataset that can be sampled from quickly while also\n",
    "    # allowing to create new labels at the same time.\n",
    "    def __init__(self, path_file, training=True):\n",
    "        # Download the tfrecord files containing the omniglot data and convert to a\n",
    "        # dataset.\n",
    "        self.data = {}\n",
    "        \n",
    "        class_names = [\"normal\"] if training else [\"normal\", \"defect\"]\n",
    "        filenames, labels = read_data_with_labels(path_file, class_names)\n",
    "        # if training == False:\n",
    "        #     print(\"length: \", len(filenames))\n",
    "        ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        self.ds = ds.shuffle(buffer_size=10240)\n",
    "\n",
    "\n",
    "        for image, label in ds.map(extraction):\n",
    "            image = image.numpy()\n",
    "            label = str(label.numpy())\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(image)\n",
    "        self.labels = list(self.data.keys())\n",
    "\n",
    "    def get_mini_dataset(\n",
    "        self, batch_size, repetitions, shots, num_classes, split=False\n",
    "    ):\n",
    "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "        temp_images = np.zeros(shape=(num_classes * shots, IMG_H, IMG_W, IMG_C))\n",
    "        if split:\n",
    "            test_labels = np.zeros(shape=(num_classes))\n",
    "            test_images = np.zeros(shape=(num_classes, IMG_H, IMG_W, IMG_C))\n",
    "\n",
    "        # Get a random subset of labels from the entire label set.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # Use enumerated index value as a temporary label for mini-batch in\n",
    "            # few shot learning.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # If creating a split dataset for testing, select an extra sample from each\n",
    "            # label to create the test dataset.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                images_to_split = random.choices(\n",
    "                    self.data[label_subset[class_idx]], k=shots + 1\n",
    "                )\n",
    "                test_images[class_idx] = images_to_split[-1]\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = images_to_split[:-1]\n",
    "            else:\n",
    "                # For each index in the randomly selected label_subset, sample the\n",
    "                # necessary number of images.\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "        )\n",
    "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
    "        \n",
    "        if split:\n",
    "            return dataset, test_images, test_labels\n",
    "        return dataset\n",
    "    \n",
    "    def get_dataset(self, batch_size):\n",
    "        ds = self.ds.map(extraction, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()  # Disable SSL warnings that may happen during download.\n",
    "train_dataset = Dataset(\"data/numbers/train_data\", training=True)\n",
    "test_dataset = Dataset(\"data/numbers/test_data\", training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff0229-24d5-497f-9aad-ecc78421b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(nrows=2, ncols=5, figsize=(20, 20))\n",
    "\n",
    "sample_keys = list(test_dataset.data.keys())\n",
    "# print(sample_keys)\n",
    "for a in range(2):\n",
    "    for b in range(5):\n",
    "        temp_image = test_dataset.data[sample_keys[a]][b]\n",
    "        temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n",
    "        temp_image *= 255\n",
    "        temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "        if b == 2:\n",
    "            axarr[a, b].set_title(\"Class : \" + sample_keys[a])\n",
    "        axarr[a, b].imshow(temp_image)\n",
    "        axarr[a, b].xaxis.set_visible(False)\n",
    "        axarr[a, b].yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9da365-5389-47a1-aadc-18bc0ba50f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, num_filters, kernel_size, padding=\"same\", act=True):\n",
    "    x = tf.keras.layers.Conv2D(num_filters, kernel_size, padding=padding, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if act:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def multires_block(x, num_filters, alpha=1.67):\n",
    "    W = num_filters * alpha\n",
    "\n",
    "    x0 = x\n",
    "    x1 = conv_block(x0, int(W*0.167), 3)\n",
    "    x2 = conv_block(x1, int(W*0.333), 3)\n",
    "    x3 = conv_block(x2, int(W*0.5), 3)\n",
    "    xc = tf.keras.layers.Concatenate()([x1, x2, x3])\n",
    "    xc = tf.keras.layers.BatchNormalization()(xc)\n",
    "\n",
    "    nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n",
    "    sc = conv_block(x0, nf, 1, act=False)\n",
    "\n",
    "    x = tf.keras.layers.Activation(\"relu\")(xc + sc)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def res_path(x, num_filters, length):\n",
    "    for i in range(length):\n",
    "        x0 = x\n",
    "        x1 = conv_block(x0, num_filters, 3, act=False)\n",
    "        sc = conv_block(x0, num_filters, 1, act=False)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x1 + sc)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, num_filters, length):\n",
    "    x = multires_block(x, num_filters)\n",
    "    s = res_path(x, num_filters, length)\n",
    "    p = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    return s, p\n",
    "\n",
    "def decoder_block(x, skip, num_filters):\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "    x = multires_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d024932-538d-407b-8c26-d9d0e6da869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, batch_size, real_images, fake_images):\n",
    "    \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, IMG_C], 0.0, 1.0)\n",
    "    diff = fake_images - real_images\n",
    "    interpolated = real_images + alpha * diff\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426bae8-7541-4974-9364-c3a05098faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multiresunet(input_shape):\n",
    "    \n",
    "    f = [8, 16, 32, 64, 128]\n",
    "    if IMG_H == 256:\n",
    "        f = [32, 64, 128, 256, 512]\n",
    "    elif IMG_H == 128:\n",
    "        f = [16, 32, 64, 128, 256]\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    p0 = input_shape\n",
    "    s1, p1 = encoder_block(p0, f[0], 4)\n",
    "    s2, p2 = encoder_block(p1, f[1], 3)\n",
    "    s3, p3 = encoder_block(p2, f[2], 2)\n",
    "    s4, p4 = encoder_block(p3, f[3], 1)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = multires_block(p4, f[4])\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, f[3])\n",
    "    d2 = decoder_block(d1, s3, f[2])\n",
    "    d3 = decoder_block(d2, s2, f[1])\n",
    "    d4 = decoder_block(d3, s1, f[0])\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = tf.keras.layers.Conv2D(3, 1, padding=\"same\", activation=\"tanh\")(d4)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = tf.keras.models.Model(inputs, outputs, name=\"MultiResUNET\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9aad2-6f9e-40b4-94ab-3c965a4a6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create discriminator model\n",
    "def build_discriminator(inputs):\n",
    "    f = [2**i for i in range(4)]\n",
    "    x = inputs\n",
    "    for i in range(0, 4):\n",
    "        x = tf.keras.layers.SeparableConvolution2D(f[i] * IMG_H ,kernel_size= (3, 3), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    \n",
    "    feature = x\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    # output = tf.keras.layers.Dense(1)(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"tanh\")(x)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs = [feature, output])\n",
    "    \n",
    "    return model\n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9426ffa-de9f-4864-bc32-33134a1b0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, batch_size, real_images, fake_images):\n",
    "    \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, IMG_C], 0.0, 1.0)\n",
    "    diff = fake_images - real_images\n",
    "    interpolated = real_images + alpha * diff\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4daa4c-f180-4134-ab4d-372cadd211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_H, IMG_W, IMG_C)\n",
    "# set input \n",
    "inputs = tf.keras.layers.Input(input_shape, name=\"input_1\")\n",
    "d_model = build_discriminator(inputs)\n",
    "g_model = build_multiresunet(inputs)\n",
    "d_model.compile()\n",
    "g_model.compile()\n",
    "\n",
    "g_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
    "d_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920087d-5202-4ef1-8ad8-13e33e71a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADV_REG_RATE_LF = 1\n",
    "REC_REG_RATE_LF = 50\n",
    "SSIM_REG_RATE_LF = 10\n",
    "FEAT_REG_RATE_LF = 1\n",
    "\n",
    "GP_LF = 10\n",
    "\n",
    "gen_loss_list = []\n",
    "disc_loss_list = []\n",
    "iter_list = []\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826985e9-9daa-4833-99d2-7c5fd97345b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    print(\"Start Trainning. \", name_model)\n",
    "    for meta_iter in range(meta_iters):\n",
    "        frac_done = meta_iter / meta_iters\n",
    "        cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "        # Temporarily save the weights from the model.\n",
    "        d_old_vars = d_model.get_weights()\n",
    "        g_old_vars = g_model.get_weights()\n",
    "        # Get a sample from the full dataset.\n",
    "        mini_dataset = train_dataset.get_mini_dataset(\n",
    "            inner_batch_size, inner_iters, train_shots, classes\n",
    "        )\n",
    "        gen_loss_out = 0.0\n",
    "        disc_loss_out = 0.0\n",
    "        for images, labels in mini_dataset:\n",
    "\n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                # tf.print(\"Images: \", images)\n",
    "                reconstructed_images = g_model(images, training=True)\n",
    "                feature_real, label_real = d_model(images, training=True)\n",
    "                # print(generated_images.shape)\n",
    "                feature_fake, label_fake = d_model(reconstructed_images, training=True)\n",
    "\n",
    "                # Loss 1: ADVERSARIAL loss\n",
    "                # use wessertein loss\n",
    "                loss_gen_w = generator_wassertein_loss(label_fake)\n",
    "\n",
    "                loss_disc_w = discriminator_wassertein_loss(label_real, label_fake) + gradient_penalty(d_model, inner_batch_size, images, reconstructed_images) * GP_LF\n",
    "\n",
    "    #             gen_adv_loss = cross_entropy(fake_output, tf.ones_like(fake_output))\n",
    "\n",
    "                # Loss 2: RECONSTRUCTION loss (L1)\n",
    "                loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "\n",
    "                # Loss 3: SSIM Loss\n",
    "                loss_ssim =  ssim(images, reconstructed_images)\n",
    "\n",
    "                # Loss 4: FEATURE Loss\n",
    "    #             loss_feat = tf.reduce_mean(mse(real_output, fake_output))\n",
    "                loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "                gen_loss = tf.reduce_mean( (loss_gen_w * ADV_REG_RATE_LF) + (loss_rec * REC_REG_RATE_LF) + (loss_ssim * SSIM_REG_RATE_LF) + (loss_feat * FEAT_REG_RATE_LF) )\n",
    "                disc_loss = tf.reduce_mean( (loss_disc_w * ADV_REG_RATE_LF) + (loss_feat *FEAT_REG_RATE_LF) )\n",
    "    #             disc_loss = adv_loss\n",
    "\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, d_model.trainable_variables)\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, g_model.trainable_variables)\n",
    "\n",
    "            gen_loss_out = gen_loss\n",
    "            disc_loss_out = disc_loss\n",
    "\n",
    "            d_optimizer.apply_gradients(zip(gradients_of_discriminator, d_model.trainable_variables))\n",
    "            g_optimizer.apply_gradients(zip(gradients_of_generator, g_model.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        d_new_vars = d_model.get_weights()\n",
    "        g_new_vars = g_model.get_weights()\n",
    "\n",
    "        # Perform SGD for the meta step.\n",
    "        for var in range(len(d_new_vars)):\n",
    "            d_new_vars[var] = d_old_vars[var] + (\n",
    "                (d_new_vars[var] - d_old_vars[var]) * cur_meta_step_size\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        for var in range(len(g_new_vars)):\n",
    "            g_new_vars[var] = g_old_vars[var] + (\n",
    "                (g_new_vars[var] - g_old_vars[var]) * cur_meta_step_size\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        # After the meta-learning step, reload the newly-trained weights into the model.\n",
    "        g_model.set_weights(g_new_vars)\n",
    "        d_model.set_weights(d_new_vars)\n",
    "        # Evaluation loop\n",
    "\n",
    "        if meta_iter % eval_interval == 0:\n",
    "\n",
    "            if meta_iter % 100 == 0:\n",
    "\n",
    "                iter_list = np.append(iter_list, meta_iter)\n",
    "                gen_loss_list = np.append(gen_loss_list, gen_loss_out)\n",
    "                disc_loss_list = np.append(disc_loss_list, disc_loss_out)\n",
    "\n",
    "                # range between 0-1\n",
    "                anomaly_weight = 0.1\n",
    "\n",
    "                scores_ano = []\n",
    "                real_label = []\n",
    "\n",
    "\n",
    "                i = 0\n",
    "                test_ds = test_dataset.get_dataset(1)\n",
    "\n",
    "                d_old_vars = d_model.get_weights()\n",
    "                g_old_vars = g_model.get_weights()\n",
    "\n",
    "                for images, labels in test_ds:\n",
    "                    # print(i)\n",
    "                    i += 1\n",
    "\n",
    "                    reconstructed_images = g_model(images, training=False)\n",
    "                    feature_real, label_real  = d_model(images, training=False)\n",
    "                    # print(generated_images.shape)\n",
    "                    feature_fake, label_fake = d_model(reconstructed_images, training=False)\n",
    "\n",
    "\n",
    "                    # Loss 2: RECONSTRUCTION loss (L1)\n",
    "                    loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "\n",
    "                    loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "                    # Loss 3: SSIM Loss\n",
    "                    loss_ssim =  ssim(images, reconstructed_images)\n",
    "\n",
    "                    score = (anomaly_weight * loss_rec) + ((1-anomaly_weight) * loss_feat)\n",
    "\n",
    "                    scores_ano = np.append(scores_ano, score.numpy())\n",
    "                    real_label = np.append(real_label, labels.numpy()[0])\n",
    "\n",
    "                ''' Scale scores vector between [0, 1]'''\n",
    "                scores_ano = (scores_ano - scores_ano.min())/(scores_ano.max()-scores_ano.min())\n",
    "\n",
    "                auc_out, _ = roc(real_label, scores_ano, name_model)\n",
    "                auc_list = np.append(auc_list, auc_out)\n",
    "\n",
    "\n",
    "\n",
    "    #             scores_ano = (scores_ano > threshold).astype(int)\n",
    "    #             # print(\"real label: \", real_label)\n",
    "    #             # print(\"anomaly score: \", scores_ano)\n",
    "    #             cm = tf.math.confusion_matrix(labels=real_label, predictions=scores_ano).numpy()\n",
    "\n",
    "    #             # TP = cm[1][1]\n",
    "    #             # FP = cm[0][1]\n",
    "    #             # FN = cm[1][0]\n",
    "    #             # TN = cm[0][0]\n",
    "\n",
    "\n",
    "    #             diagonal_sum = cm.trace()\n",
    "    #             sum_of_all_elements = cm.sum()\n",
    "\n",
    "                # print(\"Accuracy: \", diagonal_sum / sum_of_all_elements )\n",
    "        #         print(\"False Alarm Rate: \", FP/(FP+TP))\n",
    "        #         print(\"Leakage Rate: \", FN/(FN+TN))\n",
    "        #         print(\"precision_score: \",precision_score(real_label, scores_ano))\n",
    "        # #         print(\"recall_score: \", recall_score(real_label, scores_ano))\n",
    "        #         print(\"recall_score: \", TP/(TP+FN))\n",
    "        # #         F1 = 2 * (precision * recall) / (precision + recall)\n",
    "        #         print(\"F1-Score: \", f1_score(real_label, scores_ano))\n",
    "\n",
    "                print(\n",
    "                    \"model saved. batch %d:, AUC=%f, Gen Loss=%f, Disc Loss=%f\" % (meta_iter, auc_out, gen_loss_out, disc_loss_out)\n",
    "                )\n",
    "\n",
    "                # save model's weights\n",
    "                g_model.save(g_model_path)\n",
    "                d_model.save(d_model_path)\n",
    "    \n",
    "    plot_epoch_result(iter_list, gen_loss_list, \"Generator_Loss\", name_model, \"g\")\n",
    "    plot_epoch_result(iter_list, disc_loss_list, \"Discriminator_Loss\", name_model, \"r\")\n",
    "    plot_epoch_result(iter_list, auc_list, \"AUC\", name_model, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1b622-6b6f-430a-9bac-1c4e26e2a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_gen_disc(name_model, g_model, d_model, g_model_path, d_model_path, test_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
