{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7fe4f-8dac-4522-8852-874df03b8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plot\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from random import sample \n",
    "import multiprocess as mp\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc5c16-69ab-4a70-8cde-613d801b5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_COMPOSITION_DATASET = {\n",
    "    \"top\": 50,\n",
    "    \"mid\": 50,\n",
    "    \"bottom\": 0\n",
    "}\n",
    "def get_number_by_percentage(percentage, whole):\n",
    "    return math.ceil(float(percentage)/100 * float(whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148109a9-e0a3-4268-9fe5-e98ed5391030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: array [[path_of_file <string>, label <int>]]\n",
    "output: array of path [path_of_file <string>] & array of label [label <int>]\n",
    "\"\"\"\n",
    "def selecting_images_preprocessing(images_path_array, limit_image_to_train = \"MAX\", composition={}):\n",
    "    # images_path_array = glob(images_path)\n",
    "    final_image_path = []\n",
    "    final_label = []\n",
    "    def processing_image(img_data):\n",
    "        img_path = img_data[0]\n",
    "        label = img_data[1]\n",
    "        # print(img_path, label)\n",
    "        image = cv2.imread(img_path)\n",
    "        # print(image)\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        # print(mean, image.mean())\n",
    "        # print(std, image.std())\n",
    "        data_row = {\n",
    "            \"image_path\": img_path,\n",
    "            \"mean\": image.mean(),\n",
    "            \"std\": image.std(),\n",
    "            \"class\": label\n",
    "        }\n",
    "        # print(data_row)\n",
    "        return data_row\n",
    "    \n",
    "        \n",
    "    print(\"processed number of data: \", len(images_path_array))\n",
    "    if limit_image_to_train == \"MAX\":\n",
    "        limit_image_to_train = len(images_path_array)\n",
    "            \n",
    "    df_analysis = pd.DataFrame(columns=['image_path','mean','std', 'class'])\n",
    "    \n",
    "    # multiple processing calculating std\n",
    "    \n",
    "    pool = mp.Pool(5)\n",
    "    data_rows = pool.map(processing_image, images_path_array)\n",
    "    \n",
    "    df_analysis = df_analysis.append(data_rows, ignore_index = True)\n",
    "            \n",
    "    final_df = df_analysis.sort_values(['std', 'mean'], ascending = [True, False])\n",
    "    \n",
    "    if composition == {}:\n",
    "        final_df = shuffle(final_df)\n",
    "        final_image_path = final_df['image_path'].head(limit_image_to_train).tolist()\n",
    "        final_label = final_df['class'].head(limit_image_to_train).tolist()\n",
    "    else:\n",
    "        counter_available_no_data = limit_image_to_train\n",
    "        if composition.get('top') != 0:\n",
    "            num_rows = get_number_by_percentage(composition.get('top'), limit_image_to_train)\n",
    "            if counter_available_no_data <= num_rows:\n",
    "                num_rows = counter_available_no_data\n",
    "            counter_available_no_data = counter_available_no_data - num_rows\n",
    "            \n",
    "            print(composition.get('top'), num_rows, counter_available_no_data)\n",
    "            \n",
    "            # get top data\n",
    "            final_image_path = final_image_path + final_df['image_path'].head(num_rows).tolist()\n",
    "            final_label = final_label + final_df['class'].head(num_rows).tolist()\n",
    "            \n",
    "        if composition.get('mid') != 0:\n",
    "            num_rows = get_number_by_percentage(composition.get('mid'), limit_image_to_train)\n",
    "            if counter_available_no_data <= num_rows:\n",
    "                num_rows = counter_available_no_data\n",
    "            counter_available_no_data = counter_available_no_data - num_rows\n",
    "            \n",
    "            print(composition.get('mid'), num_rows, counter_available_no_data)\n",
    "            \n",
    "            # top & mid\n",
    "            n = len(final_df.index)\n",
    "            mid_n = round(n/2)\n",
    "            mid_k = round(num_rows/2)\n",
    "\n",
    "            start = mid_n - mid_k\n",
    "            end = mid_n + mid_k\n",
    "\n",
    "            final = final_df.iloc[start:end]\n",
    "            final_image_path = final_image_path + final['image_path'].head(num_rows).tolist()\n",
    "            final_label = final_label + final['class'].head(num_rows).tolist()\n",
    "            \n",
    "        if composition.get('bottom') != 0:\n",
    "            num_rows = get_number_by_percentage(composition.get('bottom'), limit_image_to_train)\n",
    "            if counter_available_no_data <= num_rows:\n",
    "                num_rows = counter_available_no_data\n",
    "            counter_available_no_data = counter_available_no_data - num_rows\n",
    "            \n",
    "            print(composition.get('bottom'), num_rows, counter_available_no_data)\n",
    "            \n",
    "            # get bottom data\n",
    "            final_image_path = final_image_path + final_df['image_path'].tail(num_rows).tolist()\n",
    "            final_label = final_label + final_df['class'].tail(num_rows).tolist()\n",
    "    \n",
    "    \n",
    "    # clear zombies memory\n",
    "    del [[final_df, df_analysis]]\n",
    "    gc.collect()\n",
    "    \n",
    "    # print(final_image_path, final_label)\n",
    "    # print(len(final_image_path), len(final_label))\n",
    "    return final_image_path, final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f5501-7e0a-4607-9f3f-f45f1a6e07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names, training=True, limit=100):\n",
    "   \n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        path_list = []\n",
    "        class_list = []\n",
    "        \n",
    "        list_path = natsort.natsorted(os.listdir(path))\n",
    "        newarr_list_path = np.array_split(list_path, len(list_path)/1000)\n",
    "        print(\"total number of dataset\", len(list_path))\n",
    "        \n",
    "        list_path = newarr_list_path[0]\n",
    "        print(\"data taken from dataset\", len(list_path))\n",
    "        for img in tqdm(list_path):  \n",
    "            if \".DS_Store\" != img:\n",
    "                # print(img)\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "                \n",
    "                path_list.append(filpath)\n",
    "                class_list.append(class_num)\n",
    "                # image_label_list.append({filpath:class_num})\n",
    "        \n",
    "        n_samples = None\n",
    "        if limit != \"MAX\":\n",
    "            n_samples = limit\n",
    "        else: \n",
    "            n_samples = len(path_list)\n",
    "            \n",
    "        if training:\n",
    "            ''' \n",
    "            selecting by attribute of image\n",
    "            '''\n",
    "            combined = np.transpose((path_list, class_list))\n",
    "            # print(combined)\n",
    "            path_list, class_list = selecting_images_preprocessing(combined, limit_image_to_train=n_samples, composition=PERCENTAGE_COMPOSITION_DATASET)\n",
    "        \n",
    "        else:\n",
    "            ''' \n",
    "            random selecting\n",
    "            '''\n",
    "            path_list, class_list = shuffle(path_list, class_list, n_samples=n_samples ,random_state=random.randint(123, 10000))\n",
    "        \n",
    "        image_list = image_list + path_list\n",
    "        label_list = label_list + class_list\n",
    "  \n",
    "    # print(image_list, label_list)\n",
    "    \n",
    "    return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1447df-be58-426e-84e0-4844cbc1283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"normal\"]\n",
    "data_path = f\"data/mura_april/train_data\"\n",
    "filenames, labels = read_data_with_labels(data_path, class_names, training=True, limit=1000)\n",
    "print(filenames, labels)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28438274-3131-4c7c-b2fb-b35a054f13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
