{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7fe4f-8dac-4522-8852-874df03b8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plot\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from random import sample \n",
    "import multiprocess as mp\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148109a9-e0a3-4268-9fe5-e98ed5391030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: array [[path_of_file <string>, label <int>]]\n",
    "output: array of path [path_of_file <string>] & array of label [label <int>]\n",
    "\"\"\"\n",
    "def selecting_images_preprocessing(images_path_array, limit_image_to_train = \"MAX\", middle_rows=False):\n",
    "    # images_path_array = glob(images_path)\n",
    "    final_image_path = []\n",
    "    final_label = []\n",
    "    def processing_image(img_data):\n",
    "        img_path = img_data[0]\n",
    "        label = img_data[1]\n",
    "        # print(img_path, label)\n",
    "        image = cv2.imread(img_path)\n",
    "        # print(image)\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        # print(mean, image.mean())\n",
    "        # print(std, image.std())\n",
    "        data_row = {\n",
    "            \"image_path\": img_path,\n",
    "            \"mean\": image.mean(),\n",
    "            \"std\": image.std(),\n",
    "            \"class\": label\n",
    "        }\n",
    "        # print(data_row)\n",
    "        return data_row\n",
    "    \n",
    "        \n",
    "    print(\"processed number of data: \", len(images_path_array))\n",
    "    if limit_image_to_train == \"MAX\":\n",
    "        limit_image_to_train = len(images_path_array)\n",
    "            \n",
    "    df_analysis = pd.DataFrame(columns=['image_path','mean','std', 'class'])\n",
    "    \n",
    "    # multiple processing calculating std\n",
    "    # print(images_path_array)\n",
    "    # start_time = datetime.now()\n",
    "    \n",
    "    pool = mp.Pool(5)\n",
    "    data_rows = pool.map(processing_image, images_path_array)\n",
    "    # do your work here\n",
    "    \n",
    "    # end_time = datetime.now()\n",
    "    # print(f'(selecting_images_preprocessing) Duration of counting std and mean of images: {end_time - start_time}')\n",
    "    # print(data_rows)\n",
    "    \n",
    "    df_analysis = df_analysis.append(data_rows, ignore_index = True)\n",
    "    # counter += 1\n",
    "    # if counter % 100 == 0:\n",
    "    #     print(\"processed image: \", counter)\n",
    "            \n",
    "    final_df = df_analysis.sort_values(['std', 'mean'], ascending = [True, False])\n",
    "    \n",
    "    # print(len(final_df))\n",
    "    if middle_rows:\n",
    "        print(\"get data from middle row\")\n",
    "        n = len(final_df.index)\n",
    "        # print(n)\n",
    "        mid_n = round(n/2)\n",
    "        mid_k = round(limit_image_to_train/2)\n",
    "\n",
    "\n",
    "        start = mid_n - mid_k\n",
    "        end = mid_n + mid_k\n",
    "        # print(start, end)\n",
    "        final = final_df.iloc[start:end]\n",
    "        # print(final)\n",
    "        final_image_path = final['image_path'].head(limit_image_to_train).tolist()\n",
    "        final_label = final['class'].head(limit_image_to_train).tolist()\n",
    "        # final_label = final['class'].head(limit_image_to_train).tolist()\n",
    "    else:\n",
    "        print(\"get data from top bottom row\")\n",
    "\n",
    "\n",
    "        val = limit_image_to_train/2\n",
    "        first = math.floor(val)\n",
    "        second = math.ceil(val)\n",
    "        \n",
    "        \n",
    "        # top & bottom\n",
    "        # final_image_path = final_df['image_path'].head(first).tolist() + final_df['image_path'].tail(second).tolist()\n",
    "        # final_label = final_df['class'].head(first).tolist() + final_df['class'].tail(second).tolist()\n",
    "        \n",
    "                \n",
    "        # top & mid\n",
    "        n = len(final_df.index)\n",
    "        mid_n = round(n/2)\n",
    "        mid_k = round(second/2)\n",
    "\n",
    "        start = mid_n - mid_k\n",
    "        end = mid_n + mid_k\n",
    "        # print(start, end)\n",
    "        final = final_df.iloc[start:end]\n",
    "        \n",
    "        final_image_path = final_df['image_path'].head(first).tolist() + final['image_path'].head(second).tolist()\n",
    "        final_label = final_df['class'].head(first).tolist() + final['class'].head(second).tolist()\n",
    "    \n",
    "    \n",
    "    # clear zombies memory\n",
    "    del [[final_df, df_analysis]]\n",
    "    gc.collect()\n",
    "    \n",
    "    # print(final_image_path, final_label)\n",
    "    # print(len(final_image_path), len(final_label))\n",
    "    return final_image_path, final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f5501-7e0a-4607-9f3f-f45f1a6e07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names, training=True, limit=100):\n",
    "   \n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        path_list = []\n",
    "        class_list = []\n",
    "        \n",
    "        list_path = natsort.natsorted(os.listdir(path))\n",
    "        newarr_list_path = np.array_split(list_path, len(list_path)/1000)\n",
    "        print(\"total number of dataset\", len(list_path))\n",
    "        \n",
    "        list_path = newarr_list_path[0]\n",
    "        print(\"data taken from dataset\", len(list_path))\n",
    "        for img in tqdm(list_path):  \n",
    "            if \".DS_Store\" != img:\n",
    "                # print(img)\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "                \n",
    "                path_list.append(filpath)\n",
    "                class_list.append(class_num)\n",
    "                # image_label_list.append({filpath:class_num})\n",
    "        \n",
    "        n_samples = None\n",
    "        if limit != \"MAX\":\n",
    "            n_samples = limit\n",
    "        else: \n",
    "            n_samples = len(path_list)\n",
    "            \n",
    "        if training:\n",
    "            ''' \n",
    "            selecting by attribute of image\n",
    "            '''\n",
    "            combined = np.transpose((path_list, class_list))\n",
    "            # print(combined)\n",
    "            path_list, class_list = selecting_images_preprocessing(combined, limit_image_to_train=n_samples, middle_rows=False)\n",
    "        \n",
    "        else:\n",
    "            ''' \n",
    "            random selecting\n",
    "            '''\n",
    "            path_list, class_list = shuffle(path_list, class_list, n_samples=n_samples ,random_state=random.randint(123, 10000))\n",
    "        \n",
    "        image_list = image_list + path_list\n",
    "        label_list = label_list + class_list\n",
    "  \n",
    "    # print(image_list, label_list)\n",
    "    \n",
    "    return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1447df-be58-426e-84e0-4844cbc1283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"normal\"]\n",
    "data_path = f\"data/mura_april/train_data\"\n",
    "filenames, labels = read_data_with_labels(data_path, class_names, training=True, limit=13)\n",
    "print(filenames, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28438274-3131-4c7c-b2fb-b35a054f13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
