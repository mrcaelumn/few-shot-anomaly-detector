{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbb1f7-1ac7-4293-8761-b388f2ef5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import math\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397dfa5-eb65-419a-8044-4ddbac706329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet50 import build_generator_resnet50_unet\n",
    "from models.seresnet50 import build_seresnet50_unet\n",
    "from models.seresnext50 import build_seresnext50_unet\n",
    "from models.discriminator import build_discriminator\n",
    "\n",
    "from models.custom_optimizers import GCAdam\n",
    "from models.loss_func import SSIMLoss, AdversarialLoss, MultiFeatureLoss\n",
    "from models.data_augmentation import selecting_images_preprocessing, sliding_crop \\\n",
    "    , sliding_crop_and_select_one, custom_v3, enhance_image, data_augmentation_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2c223-472a-4119-bc87-73ea4e538803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter, ArgumentTypeError\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ArgumentTypeError('Boolean value expected.')\n",
    "        \n",
    "# Parse command line arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"-dn\", \"--DATASET_NAME\", default=\"mura\", help=\"name of dataset in data directory.\")\n",
    "parser.add_argument(\"-s\", \"--SHOTS\", default=20, type=int, help=\"how many data that you want to use.\")\n",
    "parser.add_argument(\"-nd\", \"--NO_DATASET\", default=0, type=int, help=\"select which number of dataset.\")\n",
    "parser.add_argument(\"-bb\", \"--BACKBONE\", default=\"seresnet50\", help=\"backbone model for generator's encoder. (resnet50, seresnet50, seresnext50)\")\n",
    "parser.add_argument(\"-mm\", \"--MODE\", default=True, type=str2bool, help=\"Mode. Train (True) or Only Test (False)\")\n",
    "parser.add_argument(\"-rtd\", \"--ROOT_DATA_DIR\", default=\"target_data\", help=\"Root directory of data\")\n",
    "parser.add_argument(\"-ted\", \"--TEST_DATA\", default=\"test_data\", help=\"Directory of test data\")\n",
    "parser.add_argument(\"-trd\", \"--TRAIN_DATA\", default=\"train_data\", help=\"Directory of train data\")\n",
    "parser.add_argument(\"-eld\", \"--EVAL_DATA\", default=\"eval_data\", help=\"Directory of evaluation data\")\n",
    "parser.add_argument(\"-rd\", \"--RESULT_DIR\", default=\"result/\", help=\"Directory of result\")\n",
    "parser.add_argument(\"-smd\", \"--SAVED_MODEL_DIR\", default=\"saved_model\", help=\"Directory of saved_model\")\n",
    "args = vars(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc299db8-c95f-470e-89ae-2f41a6cb6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(args)\n",
    "\n",
    "IMG_H = 128\n",
    "IMG_W = 128\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "winSize = (256, 256)\n",
    "stSize = 20\n",
    "\n",
    "# Weight initializers for the Generator network\n",
    "# WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "LIMIT_EVAL_IMAGES = 100\n",
    "LIMIT_TEST_IMAGES = \"MAX\"\n",
    "LIMIT_TRAIN_IMAGES = 100\n",
    "\n",
    "TRAINING_DURATION = None\n",
    "TESTING_DURATION = None\n",
    "\n",
    "NUMBER_IMAGES_SELECTED = 1000\n",
    "\n",
    "# range between 0-1\n",
    "anomaly_weight = 0.9\n",
    "\n",
    "learning_rate = 0.002\n",
    "meta_step_size = 0.25\n",
    "\n",
    "inner_batch_size = 25\n",
    "eval_batch_size = 25\n",
    "\n",
    "meta_iters = 2000\n",
    "inner_iters = 4\n",
    "\n",
    "\n",
    "train_shots = 100\n",
    "# shots = 20\n",
    "shots = args[\"SHOTS\"]\n",
    "classes = 1\n",
    "n_shots = shots\n",
    "if shots > 20 :\n",
    "    n_shots = \"few\"\n",
    "    \n",
    "# DATASET_NAME = \"mura\"\n",
    "DATASET_NAME = args[\"DATASET_NAME\"]\n",
    "# NO_DATASET = 0 # 0=0-999 images, 1=1000-1999, 2=2000-2999 so on\n",
    "NO_DATASET = args[\"NO_DATASET\"] # 0=0-999 images, 1=1000-1999, 2=2000-2999 so on\n",
    "\n",
    "PERCENTAGE_COMPOSITION_DATASET = {\n",
    "    \"top\": 70,\n",
    "    \"mid\": 20,\n",
    "    \"bottom\": 10\n",
    "}\n",
    "\n",
    "mode_colour = str(IMG_H) + \"_rgb\"\n",
    "if IMG_C == 1:\n",
    "    mode_colour = str(IMG_H) + \"_gray\"\n",
    "\n",
    "MODEL_BACKBONE = args[\"BACKBONE\"]\n",
    "SAVED_MODEL_DIR = args[\"SAVED_MODEL_DIR\"]\n",
    "name_model = f\"{mode_colour}_{DATASET_NAME}_{NO_DATASET}_{MODEL_BACKBONE}_{n_shots}_shots_mura_detection_{str(meta_iters)}\"\n",
    "g_model_path = f\"{SAVED_MODEL_DIR}/{name_model}_g_model.h5\"\n",
    "d_model_path = f\"{SAVED_MODEL_DIR}/{name_model}_d_model.h5\"\n",
    "result_folder = args[\"RESULT_DIR\"]\n",
    "\n",
    "TRAIN = args[\"MODE\"]\n",
    "# print(TRAIN, type(TRAIN))\n",
    "# if not TRAIN:\n",
    "#     g_model_path = \"saved_model/g_model_name.h5\"\n",
    "#     d_model_path = \"saved_model/d_model_name.h5\"\n",
    "\n",
    "TRAIN_DATA_DIR = args[\"TRAIN_DATA\"]\n",
    "EVAL_DATA_DIR = args[\"EVAL_DATA\"]\n",
    "TEST_DATA_DIR = args[\"TEST_DATA\"]\n",
    "\n",
    "ROOT_DATA_FOLDER = args[\"ROOT_DATA_DIR\"]\n",
    "train_data_path = f\"{ROOT_DATA_FOLDER}/{DATASET_NAME}/{TRAIN_DATA_DIR}\"\n",
    "eval_data_path = f\"{ROOT_DATA_FOLDER}/{DATASET_NAME}/{EVAL_DATA_DIR}\"\n",
    "test_data_path = f\"{ROOT_DATA_FOLDER}/{DATASET_NAME}/{TEST_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f0129-2529-4ace-bbef-848d8c4f8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, name_model):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(result_folder + name_model+'_roc_curve.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "''' calculate the auc value for lables and scores'''\n",
    "def roc(labels, scores, name_model):\n",
    "    \"\"\"Compute ROC curve and ROC area for each class\"\"\"\n",
    "    roc_auc = dict()\n",
    "    # True/False Positive Rates.\n",
    "    fpr, tpr, threshold = roc_curve(labels, scores)\n",
    "    # print(\"threshold: \", threshold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # get a threshod that perform very well.\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    # draw plot for ROC-Curve\n",
    "    plot_roc_curve(fpr, tpr, name_model)\n",
    "    \n",
    "    return roc_auc, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c231433-0c03-4a84-a2b5-d40b36825ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delcare all loss function that we will use\n",
    "# L1 Loss\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "# L2 Loss\n",
    "mse = tf.keras.losses.MeanSquaredError() \n",
    "\n",
    "multimse = MultiFeatureLoss()\n",
    "# SSIM loss\n",
    "ssim = SSIMLoss(IMG_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47377645-0e75-4ee5-881c-99f25b96b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))\n",
    "    filename = f\"samples/generated_plot_epoch-{epoch}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f84aa3-8208-4a3c-b433-d5a2d1791301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(result_folder + title+'_cm.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "def plot_epoch_result(iters, loss, name, model_name, colour):\n",
    "    plt.plot(iters, loss, colour, label=name)\n",
    "#     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Iters')\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()\n",
    "    plt.savefig(result_folder + model_name+ '_'+name+'_iters_result.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def plot_anomaly_score(score_ano, labels, name, model_name):\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "    {'predicts': score_ano,\n",
    "     'label': labels\n",
    "    })\n",
    "    \n",
    "    df_normal = df[df.label == 0]\n",
    "    sns.distplot(df_normal['predicts'],  kde=False, label='normal')\n",
    "\n",
    "    df_defect = df[df.label == 1]\n",
    "    sns.distplot(df_defect['predicts'],  kde=False, label='defect')\n",
    "    \n",
    "#     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Anomaly Scores')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.legend(prop={'size': 12})\n",
    "    plt.savefig(result_folder + model_name+ '_'+name+'_anomay_scores_dist.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def write_result(array_lines, name):\n",
    "    with open(f'{result_folder}{name}.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(array_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80474f87-23e7-4760-9a05-1d76ca4d740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names, training=True, limit=100):\n",
    "   \n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        path_list = []\n",
    "        class_list = []\n",
    "        \n",
    "        list_path = natsort.natsorted(os.listdir(path))\n",
    "        \n",
    "        if training:\n",
    "            # print(\"total number of dataset\", len(list_path))\n",
    "\n",
    "            newarr_list_path = np.array_split(list_path, math.ceil(len(list_path)/NUMBER_IMAGES_SELECTED))\n",
    "\n",
    "            # print(\"number of sub dataset\", len(newarr_list_path))\n",
    "\n",
    "            list_path = newarr_list_path[NO_DATASET]\n",
    "\n",
    "            # print(\"data taken from dataset\", len(list_path))\n",
    "        \n",
    "        \n",
    "        for img in tqdm(list_path, desc='selecting images'):  \n",
    "            if \".DS_Store\" != img:\n",
    "                # print(img)\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "                \n",
    "                path_list.append(filpath)\n",
    "                class_list.append(class_num)\n",
    "                # image_label_list.append({filpath:class_num})\n",
    "        \n",
    "        n_samples = None\n",
    "        if limit != \"MAX\":\n",
    "            n_samples = limit\n",
    "        else: \n",
    "            n_samples = len(path_list)\n",
    "            \n",
    "        if training:\n",
    "            ''' \n",
    "            selecting by attribute of image\n",
    "            '''\n",
    "            combined = np.transpose((path_list, class_list))\n",
    "            # print(combined)\n",
    "            path_list, class_list = selecting_images_preprocessing(combined, limit_image_to_train=n_samples, composition=PERCENTAGE_COMPOSITION_DATASET)\n",
    "        \n",
    "        else:\n",
    "            ''' \n",
    "            random selecting\n",
    "            '''\n",
    "            # if class_n == \"defect\":\n",
    "            #     n_samples = 300\n",
    "            path_list, class_list = shuffle(path_list, class_list, n_samples=n_samples ,random_state=int(round(datetime.now().timestamp())))\n",
    "        \n",
    "        image_list = image_list + path_list\n",
    "        label_list = label_list + class_list\n",
    "  \n",
    "    # print(image_list, label_list)\n",
    "    \n",
    "    return image_list, label_list\n",
    "\n",
    "def prep_stage(x, train=True):\n",
    "    beta_contrast = 0.1\n",
    "    # enchance the brightness\n",
    "    x = enhance_image(x, beta_contrast)\n",
    "    # if train:\n",
    "        # x = enhance_image(x, beta_contrast)\n",
    "        # x = tfa.image.equalize(x)\n",
    "        # x = custom_v3(x)\n",
    "    # else: \n",
    "        # x = enhance_image(x, beta_contrast)\n",
    "        # x = tfa.image.equalize(x)\n",
    "        # x = custom_v3(x)      \n",
    "    return x\n",
    "\n",
    "def post_stage(x):\n",
    "    \n",
    "    x = tf.image.resize(x, (IMG_H, IMG_W))\n",
    "    # x = tf.image.resize_with_crop_or_pad(x, IMG_H, IMG_W)\n",
    "    # normalize to the range -1,1\n",
    "    # x = tf.cast(x, tf.float32)\n",
    "    x = (x - 127.5) / 127.5\n",
    "    # normalize to the range 0-1\n",
    "    # img /= 255.0\n",
    "    return x\n",
    "\n",
    "def extraction(image, label):\n",
    "    # This function will shrink the Omniglot images to the desired size,\n",
    "    # scale pixel values and convert the RGB image to grayscale\n",
    "    img = tf.io.read_file(image)\n",
    "    img = tf.io.decode_png(img, channels=IMG_C)\n",
    "    # print(image, label)\n",
    "    # img = cv2.imread(image)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = prep_stage(img, True)\n",
    "    \n",
    "    img = sliding_crop_and_select_one(img)\n",
    "    img = post_stage(img)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "def extraction_test(image, label):\n",
    "    # This function will shrink the Omniglot images to the desired size,\n",
    "    # scale pixel values and convert the RGB image to grayscale\n",
    "    img = tf.io.read_file(image)\n",
    "    img = tf.io.decode_png(img, channels=IMG_C)\n",
    "    # img = cv2.imread(image)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = prep_stage(img, False)\n",
    "    # img = post_stage(img)\n",
    "    \n",
    "    img_list = sliding_crop(img)\n",
    "    img = [post_stage(a) for a in img_list]\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd40c6-f382-409e-822e-9fa683bf0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_gen_disc(mode, g_model_inner, d_model_inner, g_filepath, d_filepath, test_data_path):\n",
    "    print(\"Start Checking Reconstructed Image\")\n",
    "    g_model_inner.load_weights(g_filepath)\n",
    "    d_model_inner.load_weights(d_filepath)\n",
    "    \n",
    "    normal_image = glob(test_data_path+\"/normal/*.png\")[0]\n",
    "    defect_image = glob(test_data_path+\"/defect/*.png\")[0]\n",
    "    paths = {\n",
    "        \"normal\": normal_image,\n",
    "        \"defect\": defect_image,\n",
    "    }\n",
    "\n",
    "    for i, v in paths.items():\n",
    "        print(i,v)\n",
    "\n",
    "        rows = 1\n",
    "        cols = 3\n",
    "        axes=[]\n",
    "        fig = plt.figure()\n",
    "\n",
    "        img, label = extraction(v, i)\n",
    "       \n",
    "        axes.append( fig.add_subplot(rows, cols, 1) )\n",
    "        axes[-1].set_title('_original_')  \n",
    "        \n",
    "        img = np.clip(img.numpy(), 0, 1)\n",
    "        \n",
    "        plt.imshow(img.astype(np.uint8), alpha=1.0)\n",
    "        plt.axis('off')\n",
    "\n",
    "        img = tf.cast(img, tf.float64)\n",
    "        img = (img - 127.5) / 127.5\n",
    "\n",
    "        image = tf.reshape(img, (-1, IMG_H, IMG_W, IMG_C))\n",
    "        reconstructed_images = g_model_inner.predict(image)\n",
    "        reconstructed_images = tf.reshape(reconstructed_images, (IMG_H, IMG_W, IMG_C))\n",
    "        reconstructed_images = reconstructed_images * 127 + 127\n",
    "        axes.append( fig.add_subplot(rows, cols, 3) )\n",
    "        axes[-1].set_title('_reconstructed_') \n",
    "        \n",
    "        reconstructed_images = np.clip(reconstructed_images.numpy(), 0, 1)\n",
    "        \n",
    "        plt.imshow(reconstructed_images.astype(np.uint8), alpha=1.0)\n",
    "        plt.axis('off')\n",
    "\n",
    "        fig.tight_layout()    \n",
    "        fig.savefig(result_folder + mode+'_'+i+'.png')\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241a868-2a33-42de-b550-605c148710c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # This class will facilitate the creation of a few-shot dataset\n",
    "    # from the Omniglot dataset that can be sampled from quickly while also\n",
    "    # allowing to create new labels at the same time.\n",
    "    def __init__(self, path_file, training=True, limit=100):\n",
    "        # Download the tfrecord files containing the omniglot data and convert to a\n",
    "        # dataset.\n",
    "        start_time = datetime.now()\n",
    "        self.data = {}\n",
    "        class_names = [\"normal\"] if training else [\"normal\", \"defect\"]\n",
    "        filenames, labels = read_data_with_labels(path_file, class_names, training, limit)\n",
    "        \n",
    "        ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        self.ds = ds.shuffle(buffer_size=1024, seed=random.randint(123, 10000) )\n",
    "             \n",
    "        if training:\n",
    "            for image, label in ds.map(extraction):\n",
    "                image = image.numpy()\n",
    "                label = str(label.numpy())\n",
    "                if label not in self.data:\n",
    "                    self.data[label] = []\n",
    "                self.data[label].append(image)\n",
    "            self.labels = list(self.data.keys())\n",
    "            \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        print('classes: ', class_names)\n",
    "        print(f'(Loading Dataset and Preprocessing) Duration of counting std and mean of images: {end_time - start_time}')\n",
    "        \n",
    "\n",
    "    def get_mini_dataset(\n",
    "        self, batch_size, repetitions, shots, num_classes, split=False\n",
    "    ):\n",
    "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "        temp_images = np.zeros(shape=(num_classes * shots, IMG_H, IMG_W, IMG_C))\n",
    "        if split:\n",
    "            test_labels = np.zeros(shape=(num_classes))\n",
    "            test_images = np.zeros(shape=(num_classes, IMG_H, IMG_W, IMG_C))\n",
    "\n",
    "        # Get a random subset of labels from the entire label set.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # Use enumerated index value as a temporary label for mini-batch in\n",
    "            # few shot learning.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # If creating a split dataset for testing, select an extra sample from each\n",
    "            # label to create the test dataset.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                images_to_split = random.choices(\n",
    "                    self.data[label_subset[class_idx]], k=shots + 1\n",
    "                )\n",
    "                test_images[class_idx] = images_to_split[-1]\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = images_to_split[:-1]\n",
    "            else:\n",
    "                # For each index in the randomly selected label_subset, sample the\n",
    "                # necessary number of images.\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "        )\n",
    "        dataset = dataset.shuffle(shots, seed=int(round(datetime.now().timestamp()))).batch(batch_size).repeat(repetitions)\n",
    "        \n",
    "        if split:\n",
    "            return dataset, test_images, test_labels\n",
    "        return dataset\n",
    "    \n",
    "    def get_dataset(self, batch_size):\n",
    "        ds = self.ds.map(extraction_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        # ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings() # Disable SSL warnings that may happen during download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e73e8-1d68-4219-adf7-d8b35c38bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_H, IMG_W, IMG_C)\n",
    "# set input \n",
    "inputs = tf.keras.layers.Input(input_shape, name=\"input_1\")\n",
    "\n",
    "g_model = build_seresnet50_unet(input_shape, IMG_H, IMG_C)\n",
    "d_model = build_discriminator(inputs, IMG_H)\n",
    "data_aug = data_augmentation_layers(IMG_H, IMG_W)\n",
    "\n",
    "if args[\"BACKBONE\"] == \"resnet50\":\n",
    "    print(\"backbone selected: resnet50\")\n",
    "    g_model = build_generator_resnet50_unet(input_shape, IMG_H, IMG_C)\n",
    "    \n",
    "elif args[\"BACKBONE\"] == \"seresnext50\":\n",
    "    print(\"backbone selected: seresnext50\")\n",
    "    g_model = build_seresnext50_unet(input_shape, IMG_H, IMG_C)\n",
    "    \n",
    "else:\n",
    "    print(\"backbone selected (default): seresnext50\")\n",
    "    g_model = build_seresnet50_unet(input_shape, IMG_H, IMG_C)\n",
    "    \n",
    "# d_model.summary()\n",
    "# g_model.summary()\n",
    "\n",
    "d_model.compile()\n",
    "g_model.compile()\n",
    "\n",
    "g_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
    "# g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "d_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
    "# d_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff0229-24d5-497f-9aad-ecc78421b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axarr = plt.subplots(nrows=2, ncols=5, figsize=(20, 20))\n",
    "# sample_keys = list(test_dataset.data.keys())\n",
    "# # print(sample_keys)\n",
    "# for a in range(2):\n",
    "#     for b in range(5):\n",
    "#         temp_image = test_dataset.data[sample_keys[a]][b]\n",
    "#         temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n",
    "#         temp_image *= 255\n",
    "#         temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "#         if b == 2:\n",
    "#             axarr[a, b].set_title(\"Class : \" + sample_keys[a])\n",
    "#         axarr[a, b].imshow(temp_image)\n",
    "#         axarr[a, b].xaxis.set_visible(False)\n",
    "#         axarr[a, b].yaxis.set_visible(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19900ec8-7ac3-441e-b030-c0e7cda96824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_a_score(out_g_model, out_d_model, images):\n",
    "    reconstructed_images = out_g_model(images, training=False)\n",
    "\n",
    "    feature_real, label_real  = out_d_model(images, training=False)\n",
    "    # print(generated_images.shape)\n",
    "    feature_fake, label_fake = out_d_model(reconstructed_images, training=False)\n",
    "\n",
    "    # Loss 2: RECONSTRUCTION loss (L1)\n",
    "    loss_rec = mae(images, reconstructed_images)\n",
    "\n",
    "    loss_feat = multimse(feature_real, feature_fake)\n",
    "    # print(\"loss_rec:\", loss_rec, \"loss_feat:\", loss_feat)\n",
    "    score = (anomaly_weight * loss_rec) + ((1-anomaly_weight) * loss_feat)\n",
    "    return score, loss_rec, loss_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9333e-3ce6-4477-b5f3-e0e377a3fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(g_model_inner, d_model_inner, g_filepath, d_filepath, test_ds):\n",
    "    class_names = [\"normal\", \"defect\"] # normal = 0, defect = 1\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    g_model_inner.load_weights(g_filepath)\n",
    "    d_model_inner.load_weights(d_filepath)\n",
    "    \n",
    "    scores_ano = []\n",
    "    real_label = []\n",
    "    rec_loss_list = []\n",
    "    feat_loss_list = []\n",
    "    # ssim_loss_list = []\n",
    "    # counter = 0\n",
    "    \n",
    "    for images, labels in tqdm(test_ds, desc='testing stages'):\n",
    "        loss_rec, loss_feat = 0.0, 0.0\n",
    "        score = 0\n",
    "        \n",
    "        # counter += 1\n",
    "        '''for normal'''\n",
    "        # temp_score, loss_rec, loss_feat = calculate_a_score(g_model_inner, d_model_inner, images)\n",
    "        # score = temp_score.numpy()\n",
    "        \n",
    "        '''for sliding images & Crop LR'''\n",
    "        for image in images:\n",
    "            r_score, r_rec_loss, r_feat_loss = calculate_a_score(g_model_inner, d_model_inner, image)\n",
    "            if r_score.numpy() > score or score == 0:\n",
    "                score = r_score.numpy()\n",
    "                loss_rec = r_rec_loss\n",
    "                loss_feat = r_feat_loss\n",
    "                \n",
    "        scores_ano = np.append(scores_ano, score)\n",
    "        real_label = np.append(real_label, labels.numpy()[0])\n",
    "        \n",
    "        rec_loss_list = np.append(rec_loss_list, loss_rec)\n",
    "        feat_loss_list = np.append(feat_loss_list, loss_feat)\n",
    "        # if (counter % 100) == 0:\n",
    "        #     print(counter, \" tested.\")\n",
    "    ''' Scale scores vector between [0, 1]'''\n",
    "    scores_ano = (scores_ano - scores_ano.min())/(scores_ano.max()-scores_ano.min())\n",
    "    \n",
    "    auc_out, threshold = roc(real_label, scores_ano, name_model)\n",
    "    print(\"auc: \", auc_out)\n",
    "    print(\"threshold: \", threshold)\n",
    "    \n",
    "    # histogram distribution of anomaly scores\n",
    "    plot_anomaly_score(scores_ano, real_label, \"anomaly_score_dist\", name_model)\n",
    "    \n",
    "    scores_ano = (scores_ano > threshold).astype(int)\n",
    "    cm = tf.math.confusion_matrix(labels=real_label, predictions=scores_ano).numpy()\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TN = cm[0][0]\n",
    "    # print(cm)\n",
    "    print(\n",
    "            \"model saved. TP %d:, FP=%d, FN=%d, TN=%d\" % (TP, FP, FN, TN)\n",
    "    )\n",
    "    plot_confusion_matrix(cm, class_names, title=name_model)\n",
    "\n",
    "    diagonal_sum = cm.trace()\n",
    "    sum_of_all_elements = cm.sum()\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    TESTING_DURATION = end_time - start_time\n",
    "    print(f'Duration of Testing: {end_time - start_time}')\n",
    "    arr_result = [\n",
    "        f\"Model Spec: {name_model}\",\n",
    "        f\"AUC: {auc_out}\",\n",
    "        f\"Accuracy: {(diagonal_sum / sum_of_all_elements)}\",\n",
    "        f\"False Alarm Rate (FPR): {(FP/(FP+TN))}\", \n",
    "        f\"TNR: {(TN/(FP+TN))}\", \n",
    "        f\"Precision Score (PPV): {(TP/(TP+FP))}\", \n",
    "        f\"Recall Score (TPR): {(TP/(TP+FN))}\", \n",
    "        f\"NPV: {(TN/(FN+TN))}\", \n",
    "        f\"F1-Score: {(f1_score(real_label, scores_ano))}\", \n",
    "        f\"Training Duration: {TRAINING_DURATION}\",\n",
    "        f\"Testing Duration: {TESTING_DURATION}\"\n",
    "    ]\n",
    "    print(\"\\n\".join(arr_result))\n",
    "\n",
    "    write_result(arr_result, name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920087d-5202-4ef1-8ad8-13e33e71a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADV_REG_RATE_LF = 1\n",
    "REC_REG_RATE_LF = 50\n",
    "SSIM_REG_RATE_LF = 10\n",
    "FEAT_REG_RATE_LF = 1\n",
    "\n",
    "gen_loss_list = []\n",
    "disc_loss_list = []\n",
    "iter_list = []\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b491a4-8a36-4df0-ac01-990231e49246",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # tf.print(\"Images: \", images)\n",
    "        \n",
    "        # apply augmentation method  \n",
    "        augmented_images = data_aug(real_images)\n",
    "        \n",
    "        reconstructed_images = g_model(augmented_images, training=True)\n",
    "        \n",
    "        # real_images = grayscale_converter(real_images)\n",
    "        feature_real, label_real = d_model(augmented_images, training=True)\n",
    "        # print(generated_images.shape)\n",
    "        feature_fake, label_fake = d_model(reconstructed_images, training=True)\n",
    "\n",
    "        discriminator_fake_average_out = tf.math.reduce_mean(label_fake, axis=0)\n",
    "        discriminator_real_average_out = tf.math.reduce_mean(label_real, axis=0)\n",
    "        real_fake_ra_out = label_real - discriminator_fake_average_out\n",
    "        fake_real_ra_out = label_fake - discriminator_real_average_out\n",
    "        epsilon = 0.000001\n",
    "        \n",
    "        # Loss 1: \n",
    "        # use relativistic average loss\n",
    "        loss_gen_ra = -( \n",
    "            tf.math.reduce_mean( \n",
    "                tf.math.log( \n",
    "                    tf.math.sigmoid(fake_real_ra_out) + epsilon), axis=0 \n",
    "            ) + tf.math.reduce_mean( \n",
    "                tf.math.log(1-tf.math.sigmoid(real_fake_ra_out) + epsilon), axis=0 \n",
    "            ) \n",
    "        )\n",
    "\n",
    "        loss_disc_ra = -( \n",
    "            tf.math.reduce_mean( \n",
    "                tf.math.log(\n",
    "                    tf.math.sigmoid(real_fake_ra_out) + epsilon), axis=0 \n",
    "            ) + tf.math.reduce_mean( \n",
    "                tf.math.log(1-tf.math.sigmoid(fake_real_ra_out) + epsilon), axis=0 \n",
    "            ) \n",
    "        )\n",
    "\n",
    "        # Loss 2: RECONSTRUCTION loss (L1)\n",
    "        loss_rec = mae(augmented_images, reconstructed_images)\n",
    "\n",
    "        # Loss 3: SSIM Loss\n",
    "        loss_ssim =  ssim(augmented_images, reconstructed_images)\n",
    "\n",
    "        # Loss 4: FEATURE Loss\n",
    "        # loss_feat = mse(feature_real, feature_fake)\n",
    "        loss_feat = multimse(feature_real, feature_fake, FEAT_REG_RATE_LF)\n",
    "\n",
    "        gen_loss = tf.reduce_mean( \n",
    "            (loss_gen_ra * ADV_REG_RATE_LF) \n",
    "            + (loss_rec * REC_REG_RATE_LF) \n",
    "            + (loss_ssim * SSIM_REG_RATE_LF) \n",
    "            + (loss_feat) \n",
    "        )\n",
    "\n",
    "        disc_loss = tf.reduce_mean( (loss_disc_ra * ADV_REG_RATE_LF) + (loss_feat * FEAT_REG_RATE_LF) )\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, d_model.trainable_variables)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, g_model.trainable_variables)\n",
    "\n",
    "    d_optimizer.apply_gradients(zip(gradients_of_discriminator, d_model.trainable_variables))\n",
    "    g_optimizer.apply_gradients(zip(gradients_of_generator, g_model.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826985e9-9daa-4833-99d2-7c5fd97345b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    print(\"Start Trainning. \", name_model)\n",
    "    \n",
    "    ## load dataset\n",
    "    train_dataset = Dataset(train_data_path, training=True, limit=LIMIT_TRAIN_IMAGES)\n",
    "    eval_dataset = Dataset(eval_data_path, training=False, limit=LIMIT_EVAL_IMAGES)\n",
    "    eval_ds = eval_dataset.get_dataset(1)\n",
    "\n",
    "    gc.collect()\n",
    "    standard_auc = 0.8\n",
    "    best_auc = standard_auc\n",
    "    delay_ref = 3\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    # for meta_iter in tqdm(range(meta_iters), desc=f'training process'):\n",
    "    for meta_iter in range(meta_iters):\n",
    "        frac_done = meta_iter / meta_iters\n",
    "        cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "        # Temporarily save the weights from the model.\n",
    "        d_old_vars = d_model.get_weights()\n",
    "        g_old_vars = g_model.get_weights()\n",
    "        # Get a sample from the full dataset.\n",
    "        mini_dataset = train_dataset.get_mini_dataset(\n",
    "            inner_batch_size, inner_iters, train_shots, classes\n",
    "        )\n",
    "        gen_loss_out = 0.0\n",
    "        disc_loss_out = 0.0\n",
    "        \n",
    "        # print(\"meta_iter: \", meta_iter)\n",
    "        for images, _ in mini_dataset:\n",
    "            \n",
    "            g_loss, d_loss = train_step(images)\n",
    "            gen_loss_out = g_loss\n",
    "            disc_loss_out = d_loss\n",
    "            \n",
    "        d_new_vars = d_model.get_weights()\n",
    "        g_new_vars = g_model.get_weights()\n",
    "\n",
    "        # Perform SGD for the meta step.\n",
    "        for var in range(len(d_new_vars)):\n",
    "            d_new_vars[var] = d_old_vars[var] + (\n",
    "                (d_new_vars[var] - d_old_vars[var]) * cur_meta_step_size\n",
    "            )\n",
    "\n",
    "        for var in range(len(g_new_vars)):\n",
    "            g_new_vars[var] = g_old_vars[var] + (\n",
    "                (g_new_vars[var] - g_old_vars[var]) * cur_meta_step_size\n",
    "            )\n",
    "\n",
    "        # After the meta-learning step, reload the newly-trained weights into the model.\n",
    "        g_model.set_weights(g_new_vars)\n",
    "        d_model.set_weights(d_new_vars)\n",
    "        \n",
    "        # Evaluation loop\n",
    "        meta_iter = meta_iter + 1\n",
    "        if meta_iter % 100 == 0:\n",
    "            eval_g_model = g_model\n",
    "            eval_d_model = d_model\n",
    "            \n",
    "            iter_list = np.append(iter_list, meta_iter)\n",
    "            gen_loss_list = np.append(gen_loss_list, gen_loss_out)\n",
    "            disc_loss_list = np.append(disc_loss_list, disc_loss_out)\n",
    "\n",
    "            scores_ano = []\n",
    "            real_label = []\n",
    "            # counter = 0\n",
    "           \n",
    "            for images, labels in tqdm(eval_ds, desc=f'evalution stage at {meta_iter} batch'):\n",
    "\n",
    "                loss_rec, loss_feat = 0.0, 0.0\n",
    "                score = 0\n",
    "                # counter += 1\n",
    "                \n",
    "                '''for normal'''\n",
    "                # temp_score, loss_rec, loss_feat = calculate_a_score(eval_g_model, eval_d_model, images)\n",
    "                # score = temp_score.numpy()\n",
    "\n",
    "                '''for Sliding Images & LR Crop'''\n",
    "                for image in images:\n",
    "                    r_score, r_rec_loss, r_feat_loss = calculate_a_score(eval_g_model, eval_d_model, image)\n",
    "                    if r_score.numpy() > score or score == 0:\n",
    "                        score = r_score.numpy()\n",
    "                        loss_rec = r_rec_loss\n",
    "                        loss_feat = r_feat_loss\n",
    "                    \n",
    "                scores_ano = np.append(scores_ano, score)\n",
    "                real_label = np.append(real_label, labels.numpy()[0])\n",
    "                # if (counter % 100) == 0:\n",
    "                #     print(counter, \" tested.\")\n",
    "            # print(\"scores_ano:\", scores_ano)\n",
    "            '''Scale scores vector between [0, 1]'''\n",
    "            scores_ano = (scores_ano - scores_ano.min())/(scores_ano.max()-scores_ano.min())\n",
    "            # print(\"real_label:\", real_label)\n",
    "            # print(\"scores_ano:\", scores_ano)\n",
    "            auc_out, threshold = roc(real_label, scores_ano, name_model)\n",
    "            auc_list = np.append(auc_list, auc_out)\n",
    "            scores_ano = (scores_ano > threshold).astype(int)\n",
    "            cm = tf.math.confusion_matrix(labels=real_label, predictions=scores_ano).numpy()\n",
    "            TP = cm[1][1]\n",
    "            FP = cm[0][1]\n",
    "            FN = cm[1][0]\n",
    "            TN = cm[0][0]\n",
    "            # print(cm)\n",
    "            print(\n",
    "                f\"model saved. batch {meta_iter}:, AUC={auc_out:.3f}, TP={TP}, TN={TN}, FP={FP}, FN={FN}, Gen Loss={gen_loss_out:.5f}, Disc Loss={disc_loss_out:.5f}\" \n",
    "            )\n",
    "            \n",
    "            if auc_out >= best_auc or auc_out > standard_auc:\n",
    "                print(\n",
    "                    f\"the best model saved. at batch {meta_iter}: with AUC={auc_out:.3f}\"\n",
    "                )\n",
    "                \n",
    "                best_g_model_path = g_model_path.replace(\".h5\", f\"_best_{meta_iter}_{auc_out:.2f}.h5\")\n",
    "                best_d_model_path = d_model_path.replace(\".h5\", f\"_best_{meta_iter}_{auc_out:.2f}.h5\")\n",
    "                g_model.save(best_g_model_path)\n",
    "                d_model.save(best_d_model_path)\n",
    "                best_auc = auc_out\n",
    "                \n",
    "            # save model's weights\n",
    "            g_model.save(g_model_path)\n",
    "            d_model.save(d_model_path)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    TRAINING_DURATION = end_time - start_time\n",
    "    print(f'Duration of Training: {end_time - start_time}')\n",
    "    \"\"\"\n",
    "    Train Ends\n",
    "    \"\"\"\n",
    "    plot_epoch_result(iter_list, gen_loss_list, \"Generator_Loss\", name_model, \"g\")\n",
    "    plot_epoch_result(iter_list, disc_loss_list, \"Discriminator_Loss\", name_model, \"r\")\n",
    "    plot_epoch_result(iter_list, auc_list, \"AUC_Score\", name_model, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1b622-6b6f-430a-9bac-1c4e26e2a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(test_data_path, training=False, limit=LIMIT_TEST_IMAGES)\n",
    "testing(g_model, d_model, g_model_path, d_model_path, test_dataset.get_dataset(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0adf8-c786-4836-9aa0-df8c2781f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_gen_disc(name_model, g_model, d_model, g_model_path, d_model_path, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e5407-e31e-4710-a290-4f8f4e5c9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
