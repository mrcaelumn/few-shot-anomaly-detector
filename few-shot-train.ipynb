{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fbb1f7-1ac7-4293-8761-b388f2ef5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc299db8-c95f-470e-89ae-2f41a6cb6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3  ## Change this to 1 for grayscale.\n",
    "\n",
    "# Weight initializers for the Generator network\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "learning_rate = 0.0001\n",
    "meta_step_size = 0.25\n",
    "\n",
    "inner_batch_size = 25\n",
    "eval_batch_size = 25\n",
    "\n",
    "meta_iters = 100\n",
    "eval_iters = 1\n",
    "inner_iters = 10\n",
    "\n",
    "eval_interval = 1\n",
    "train_shots = 20\n",
    "shots = 10\n",
    "classes = 10\n",
    "\n",
    "name_model = \"prototype_one_few_shot\"\n",
    "g_model_path = \"saved_model/g_\"+name_model+\"_\"+str(meta_iters)+\".h5\"\n",
    "d_model_path = \"saved_model/d_\"+name_model+\"_\"+str(meta_iters)+\".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828014f0-4825-4f9c-8e4e-c50bff9d4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for SSIM loss function\n",
    "class SSIMLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "         reduction=tf.keras.losses.Reduction.AUTO,\n",
    "         name='SSIMLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    def call(self, ori, recon):\n",
    "        recon = tf.convert_to_tensor(recon)\n",
    "        ori = tf.cast(ori, recon.dtype)\n",
    "\n",
    "        # Loss 3: SSIM Loss\n",
    "#         loss_ssim =  tf.reduce_mean(1 - tf.image.ssim(ori, recon, max_val=1.0)[0]) \n",
    "        loss_ssim = tf.reduce_mean(1 - tf.image.ssim(ori, recon, 2.0))\n",
    "        return loss_ssim\n",
    "    \n",
    "# class for Feature loss function\n",
    "class FeatureLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='FeatureLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, real, fake):\n",
    "        fake = tf.convert_to_tensor(fake)\n",
    "        real = tf.cast(real, fake.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        loss_feat = tf.reduce_mean(tf.pow((real-fake), 2))\n",
    "        return loss_feat\n",
    "    \n",
    "# class for Adversarial loss function\n",
    "class AdversarialLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,\n",
    "             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "             name='AdversarialLoss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "\n",
    "    \n",
    "    def call(self, logits_in, labels_in):\n",
    "        labels_in = tf.convert_to_tensor(labels_in)\n",
    "        logits_in = tf.cast(logits_in, labels_in.dtype)\n",
    "        # Loss 4: FEATURE Loss\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))\n",
    "\n",
    "# function for Generator Wassertein loss function\n",
    "\n",
    "def generator_wassertein_loss(fake_img):\n",
    "    fake = tf.convert_to_tensor(fake_img)\n",
    "    return -tf.reduce_mean(fake)\n",
    "\n",
    "# function for Discriminator Wassertein loss function\n",
    "def discriminator_wassertein_loss(real_img, fake_img):\n",
    "    fake = tf.convert_to_tensor(fake_img)\n",
    "    real = tf.cast(real_img, fake.dtype)\n",
    "    return tf.reduce_mean(fake) - tf.reduce_mean(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2f0129-2529-4ace-bbef-848d8c4f8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate the auc value for lables and scores'''\n",
    "def roc(labels, scores, name_model):\n",
    "    \"\"\"Compute ROC curve and ROC area for each class\"\"\"\n",
    "    roc_auc = dict()\n",
    "    # True/False Positive Rates.\n",
    "    fpr, tpr, threshold = roc_curve(labels, scores)\n",
    "    # print(\"threshold: \", threshold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # get a threshod that perform very well.\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    # draw plot for ROC-Curve\n",
    "    # plot_roc_curve(fpr, tpr, name_model)\n",
    "    \n",
    "    return roc_auc, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c231433-0c03-4a84-a2b5-d40b36825ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delcare all loss function that we will use\n",
    "\n",
    "# for adversarial loss\n",
    "# cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# cross_entropy = AdversarialLoss()\n",
    "\n",
    "# L1 Loss\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "# L2 Loss\n",
    "mse = tf.keras.losses.MeanSquaredError() \n",
    "feat = FeatureLoss()\n",
    "\n",
    "# SSIM loss\n",
    "ssim = SSIMLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a229876d-50de-4906-ba58-519932cfec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCAdam(tf.keras.optimizers.Adam):\n",
    "    def get_gradients(self, loss, params):\n",
    "        # We here just provide a modified get_gradients() function since we are\n",
    "        # trying to just compute the centralized gradients.\n",
    "\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= tf.reduce_mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47377645-0e75-4ee5-881c-99f25b96b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])  ## pyplot.imshow(np.squeeze(examples[i], axis=-1))\n",
    "    filename = f\"samples/generated_plot_epoch-{epoch}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa049b05-f27c-45be-949a-c362baa633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_result(iters, loss, name, model_name, colour):\n",
    "    plt.plot(epochs, loss, colour, label=name)\n",
    "#     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(model_name+ '_'+name+'_epoch_result.png')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80474f87-23e7-4760-9a05-1d76ca4d740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(filepath, class_names):\n",
    "\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for class_n in class_names:  # do dogs and cats\n",
    "        path = os.path.join(filepath,class_n)  # create path to dogs and cats\n",
    "        class_num = class_names.index(class_n)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            if \".DS_Store\" != img:\n",
    "                filpath = os.path.join(path,img)\n",
    "#                 print(filpath, class_num)\n",
    "\n",
    "                image_list.append(filpath)\n",
    "                label_list.append(class_num)\n",
    "\n",
    "    return image_list, label_list\n",
    "\n",
    "def prep_stage(x):\n",
    "    x = tf.image.resize(x, (IMG_H, IMG_W))\n",
    "    return x\n",
    "\n",
    "def extraction(image, label):\n",
    "    # This function will shrink the Omniglot images to the desired size,\n",
    "    # scale pixel values and convert the RGB image to grayscale\n",
    "    img = tf.io.read_file(image)\n",
    "    img = tf.io.decode_bmp(img, channels=IMG_C)\n",
    "    img = prep_stage(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    #     rescailing image from 0,255 to -1,1\n",
    "    img = (img - 127.5) / 127.5\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2241a868-2a33-42de-b550-605c148710c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 336441.50it/s]\n",
      "2022-02-21 19:32:52.921890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 19:32:53.038791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 387643.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 333410.49it/s]\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    # This class will facilitate the creation of a few-shot dataset\n",
    "    # from the Omniglot dataset that can be sampled from quickly while also\n",
    "    # allowing to create new labels at the same time.\n",
    "    def __init__(self, path_file, training=True):\n",
    "        # Download the tfrecord files containing the omniglot data and convert to a\n",
    "        # dataset.\n",
    "        self.data = {}\n",
    "        \n",
    "        class_names = [\"normal\"] if training else [\"normal\", \"defect\"]\n",
    "        filenames, labels = read_data_with_labels(path_file, class_names)\n",
    "        # if training == False:\n",
    "        #     print(\"length: \", len(filenames))\n",
    "        ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        self.ds = ds.shuffle(buffer_size=10240)\n",
    "\n",
    "\n",
    "        for image, label in ds.map(extraction):\n",
    "            image = image.numpy()\n",
    "            label = str(label.numpy())\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(image)\n",
    "        self.labels = list(self.data.keys())\n",
    "\n",
    "    def get_mini_dataset(\n",
    "        self, batch_size, repetitions, shots, num_classes, split=False\n",
    "    ):\n",
    "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "        temp_images = np.zeros(shape=(num_classes * shots, IMG_H, IMG_W, IMG_C))\n",
    "        if split:\n",
    "            test_labels = np.zeros(shape=(num_classes))\n",
    "            test_images = np.zeros(shape=(num_classes, IMG_H, IMG_W, IMG_C))\n",
    "\n",
    "        # Get a random subset of labels from the entire label set.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # Use enumerated index value as a temporary label for mini-batch in\n",
    "            # few shot learning.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # If creating a split dataset for testing, select an extra sample from each\n",
    "            # label to create the test dataset.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                images_to_split = random.choices(\n",
    "                    self.data[label_subset[class_idx]], k=shots + 1\n",
    "                )\n",
    "                test_images[class_idx] = images_to_split[-1]\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = images_to_split[:-1]\n",
    "            else:\n",
    "                # For each index in the randomly selected label_subset, sample the\n",
    "                # necessary number of images.\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "        )\n",
    "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
    "        \n",
    "        if split:\n",
    "            return dataset, test_images, test_labels\n",
    "        return dataset\n",
    "    \n",
    "    def get_dataset(self, batch_size):\n",
    "        ds = self.ds.map(extraction, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()  # Disable SSL warnings that may happen during download.\n",
    "train_dataset = Dataset(\"data/numbers/train_data\", training=True)\n",
    "test_dataset = Dataset(\"data/numbers/test_data\", training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeff0229-24d5-497f-9aad-ecc78421b38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axarr = plt.subplots(nrows=2, ncols=5, figsize=(20, 20))\n",
    "\n",
    "sample_keys = list(test_dataset.data.keys())\n",
    "# print(sample_keys)\n",
    "for a in range(2):\n",
    "    for b in range(5):\n",
    "        temp_image = test_dataset.data[sample_keys[a]][b]\n",
    "        temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n",
    "        temp_image *= 255\n",
    "        temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "        if b == 2:\n",
    "            axarr[a, b].set_title(\"Class : \" + sample_keys[a])\n",
    "        axarr[a, b].imshow(temp_image)\n",
    "        axarr[a, b].xaxis.set_visible(False)\n",
    "        axarr[a, b].yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9da365-5389-47a1-aadc-18bc0ba50f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = tf.keras.layers.Conv2D(num_filters, kernel_size=(3,3), padding=\"same\")(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_filters, kernel_size=(3,3), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_filters, (3, 3), strides=2, padding=\"same\")(input)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8426bae8-7541-4974-9364-c3a05098faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator model based on resnet50 and unet network\n",
    "def build_generator_resnet50_unet(input_shape):\n",
    "    # print(inputs)\n",
    "    # print(\"pretained start\")\n",
    "    \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input_shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = resnet50.get_layer(\"input_1\").output           ## (256 x 256)\n",
    "    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (128 x 128)\n",
    "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (64 x 64)\n",
    "    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (32 x 32)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (16 x 16)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    x = IMG_H\n",
    "    d1 = decoder_block(b1, s4, x)                     ## (32 x 32)\n",
    "    x = x/2\n",
    "    d2 = decoder_block(d1, s3, x)                     ## (64 x 64)\n",
    "    x = x/2\n",
    "    d3 = decoder_block(d2, s2, x)                     ## (128 x 128)\n",
    "    x = x/2\n",
    "    d4 = decoder_block(d3, s1, x)                      ## (256 x 256)\n",
    "    \n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = tf.keras.layers.Conv2D(3, 1, padding=\"same\", activation=\"tanh\")(d4)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad9aad2-6f9e-40b4-94ab-3c965a4a6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create discriminator model\n",
    "def build_discriminator(inputs):\n",
    "    f = [2**i for i in range(4)]\n",
    "    x = inputs\n",
    "    for i in range(0, 4):\n",
    "        x = tf.keras.layers.SeparableConvolution2D(f[i] * IMG_H ,kernel_size= (3, 3), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    \n",
    "    feature = x\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"tanh\")(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs = [feature, output])\n",
    "    \n",
    "    return model\n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2f99d-e347-4996-95f2-e1a4b65aae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, batch_size, real_images, fake_images):\n",
    "    \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    diff = fake_images - real_images\n",
    "    interpolated = real_images + alpha * diff\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4daa4c-f180-4134-ab4d-372cadd211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_H, IMG_W, IMG_C)\n",
    "# set input \n",
    "inputs = tf.keras.layers.Input(input_shape, name=\"input_1\")\n",
    "d_model = build_discriminator(inputs)\n",
    "g_model = build_generator_resnet50_unet(inputs)\n",
    "d_model.compile()\n",
    "g_model.compile()\n",
    "\n",
    "g_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
    "d_optimizer = GCAdam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c920087d-5202-4ef1-8ad8-13e33e71a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADV_REG_RATE_LF = 1\n",
    "REC_REG_RATE_LF = 50\n",
    "SSIM_REG_RATE_LF = 10\n",
    "FEAT_REG_RATE_LF = 1\n",
    "\n",
    "gen_loss_list = []\n",
    "disc_loss_list = []\n",
    "iter_list = []\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826985e9-9daa-4833-99d2-7c5fd97345b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved. batch 0:, AUC=0.001600, Gen Loss=47.614918, Disc Loss=0.312848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrcaelumn/YZU/.jupyter_env/lib/python3.9/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "for meta_iter in range(meta_iters):\n",
    "    frac_done = meta_iter / meta_iters\n",
    "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "    # Temporarily save the weights from the model.\n",
    "    d_old_vars = d_model.get_weights()\n",
    "    g_old_vars = g_model.get_weights()\n",
    "    # Get a sample from the full dataset.\n",
    "    mini_dataset = train_dataset.get_mini_dataset(\n",
    "        inner_batch_size, inner_iters, train_shots, classes\n",
    "    )\n",
    "    gen_loss_out = 0.0\n",
    "    disc_loss_out = 0.0\n",
    "    for images, labels in mini_dataset:\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # tf.print(\"Images: \", images)\n",
    "            reconstructed_images = g_model(images, training=True)\n",
    "            feature_real, label_real = d_model(images, training=True)\n",
    "            # print(generated_images.shape)\n",
    "            feature_fake, label_fake = d_model(reconstructed_images, training=True)\n",
    "\n",
    "       \n",
    "            # use wessertein loss\n",
    "            loss_gen_w = generator_wassertein_loss(label_fake)\n",
    "\n",
    "            loss_disc_w = discriminator_wassertein_loss(label_real, label_fake)\n",
    "            \n",
    "            \n",
    "            # Loss 2: RECONSTRUCTION loss (L1)\n",
    "            loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "        \n",
    "            # Loss 3: SSIM Loss\n",
    "            loss_ssim =  ssim(images, reconstructed_images)\n",
    "        \n",
    "            # Loss 4: FEATURE Loss\n",
    "#             loss_feat = tf.reduce_mean(mse(real_output, fake_output))\n",
    "            loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "            gen_loss = tf.reduce_mean( (loss_gen_w * ADV_REG_RATE_LF) + (loss_rec * REC_REG_RATE_LF) + (loss_ssim * SSIM_REG_RATE_LF) + (loss_feat * FEAT_REG_RATE_LF) )\n",
    "            disc_loss = tf.reduce_mean( (loss_disc_w * ADV_REG_RATE_LF) + (loss_feat * FEAT_REG_RATE_LF) )\n",
    "#             disc_loss = adv_loss\n",
    "        \n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, d_model.trainable_variables)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, g_model.trainable_variables)\n",
    "        \n",
    "        gen_loss_out = gen_loss\n",
    "        disc_loss_out = disc_loss\n",
    "        \n",
    "        d_optimizer.apply_gradients(zip(gradients_of_discriminator, d_model.trainable_variables))\n",
    "        g_optimizer.apply_gradients(zip(gradients_of_generator, g_model.trainable_variables))\n",
    "        \n",
    "    \n",
    "    \n",
    "     \n",
    "    d_new_vars = d_model.get_weights()\n",
    "    g_new_vars = g_model.get_weights()\n",
    "    \n",
    "    # Perform SGD for the meta step.\n",
    "    for var in range(len(d_new_vars)):\n",
    "        d_new_vars[var] = d_old_vars[var] + (\n",
    "            (d_new_vars[var] - d_old_vars[var]) * cur_meta_step_size\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    for var in range(len(g_new_vars)):\n",
    "        g_new_vars[var] = g_old_vars[var] + (\n",
    "            (g_new_vars[var] - g_old_vars[var]) * cur_meta_step_size\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # After the meta-learning step, reload the newly-trained weights into the model.\n",
    "    g_model.set_weights(g_new_vars)\n",
    "    d_model.set_weights(d_new_vars)\n",
    "    # Evaluation loop\n",
    "    \n",
    "    if meta_iter % eval_interval == 0:\n",
    "        \n",
    "        if meta_iter % 100 == 0:\n",
    "            \n",
    "            iter_list = np.append(iter_list, meta_iter)\n",
    "            gen_loss_list = np.append(gen_loss_list, gen_loss_out)\n",
    "            disc_loss_list = np.append(disc_loss_list, disc_loss_out)\n",
    "            \n",
    "            # range between 0-1\n",
    "            anomaly_weight = 0.1\n",
    "\n",
    "            scores_ano = []\n",
    "            real_label = []\n",
    "\n",
    "            \n",
    "            i = 0\n",
    "            test_ds = test_dataset.get_dataset(1)\n",
    "\n",
    "            d_old_vars = d_model.get_weights()\n",
    "            g_old_vars = g_model.get_weights()\n",
    "\n",
    "            for images, labels in test_ds:\n",
    "                # print(i)\n",
    "                i += 1\n",
    "            \n",
    "                reconstructed_images = g_model(images, training=False)\n",
    "                feature_real, label_real  = d_model(images, training=False)\n",
    "                # print(generated_images.shape)\n",
    "                feature_fake, label_fake = d_model(reconstructed_images, training=False)\n",
    "                \n",
    "                # Loss 2: RECONSTRUCTION loss (L1)\n",
    "                loss_rec = tf.reduce_mean(mae(images, reconstructed_images))\n",
    "\n",
    "                loss_feat = feat(feature_real, feature_fake)\n",
    "\n",
    "                # Loss 3: SSIM Loss\n",
    "                loss_ssim =  ssim(images, reconstructed_images)\n",
    "\n",
    "                score = (anomaly_weight * loss_rec) + ((1-anomaly_weight) * loss_feat)\n",
    "\n",
    "                scores_ano = np.append(scores_ano, score.numpy())\n",
    "                real_label = np.append(real_label, labels.numpy()[0])\n",
    "        \n",
    "            ''' Scale scores vector between [0, 1]'''\n",
    "            scores_ano = (scores_ano - scores_ano.min())/(scores_ano.max()-scores_ano.min())\n",
    "\n",
    "            auc_out, _ = roc(real_label, scores_ano, name_model)\n",
    "            auc_list = np.append(auc_list, auc_out)\n",
    "\n",
    "\n",
    "\n",
    "#             scores_ano = (scores_ano > threshold).astype(int)\n",
    "#             # print(\"real label: \", real_label)\n",
    "#             # print(\"anomaly score: \", scores_ano)\n",
    "#             cm = tf.math.confusion_matrix(labels=real_label, predictions=scores_ano).numpy()\n",
    "            \n",
    "#             # TP = cm[1][1]\n",
    "#             # FP = cm[0][1]\n",
    "#             # FN = cm[1][0]\n",
    "#             # TN = cm[0][0]\n",
    "           \n",
    "\n",
    "#             diagonal_sum = cm.trace()\n",
    "#             sum_of_all_elements = cm.sum()\n",
    "\n",
    "            # print(\"Accuracy: \", diagonal_sum / sum_of_all_elements )\n",
    "    #         print(\"False Alarm Rate: \", FP/(FP+TP))\n",
    "    #         print(\"Leakage Rate: \", FN/(FN+TN))\n",
    "    #         print(\"precision_score: \",precision_score(real_label, scores_ano))\n",
    "    # #         print(\"recall_score: \", recall_score(real_label, scores_ano))\n",
    "    #         print(\"recall_score: \", TP/(TP+FN))\n",
    "    # #         F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    #         print(\"F1-Score: \", f1_score(real_label, scores_ano))\n",
    "            \n",
    "            print(\n",
    "                \"model saved. batch %d:, AUC=%f, Gen Loss=%f, Disc Loss=%f\" % (meta_iter, auc_out, gen_loss_out, disc_loss_out)\n",
    "            )\n",
    "            \n",
    "            # save model's weights\n",
    "            g_model.save(g_model_path)\n",
    "            d_model.save(d_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1b622-6b6f-430a-9bac-1c4e26e2a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_result(iter_list, gen_loss_list, \"Generator_Loss\", name_model, \"g\")\n",
    "plot_epoch_result(iter_list, disc_loss_list, \"Discriminator_Loss\", name_model, \"r\")\n",
    "plot_epoch_result(iter_list, auc_list, \"AUC\", name_model, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505e43b-d711-44f4-a408-ce6515683d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
