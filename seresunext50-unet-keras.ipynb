{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd7e00-2a8e-46b7-95b0-9f8887123707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Lambda, Activation, MaxPooling2D, MaxPool2D, \\\n",
    "GlobalAveragePooling2D, Conv2DTranspose, Concatenate, \\\n",
    "Input, Dense, Reshape, Multiply, Add, Flatten, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "from keras import backend\n",
    "\n",
    "import keras_applications as ka\n",
    "\n",
    "import collections\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "ModelParams = collections.namedtuple(\n",
    "    'ModelParams',\n",
    "    ['model_name', 'repetitions', 'residual_block', 'groups',\n",
    "     'reduction', 'init_filters', 'input_3x3', 'dropout']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeed9e9-8653-42fb-93e1-c04315d9dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_params(**params):\n",
    "    axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    default_bn_params = {\n",
    "        'axis': axis,\n",
    "        'epsilon': 9.999999747378752e-06,\n",
    "    }\n",
    "    default_bn_params.update(params)\n",
    "    return default_bn_params\n",
    "\n",
    "\n",
    "def get_num_channels(tensor):\n",
    "    channels_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    return backend.int_shape(tensor)[channels_axis]\n",
    "\n",
    "def expand_dims(x, channels_axis):\n",
    "    if channels_axis == 3:\n",
    "        return x[:, None, None, :]\n",
    "    elif channels_axis == 1:\n",
    "        return x[:, :, None, None]\n",
    "    else:\n",
    "        raise ValueError(\"Slice axis should be in (1, 3), got {}.\".format(channels_axis))\n",
    "        \n",
    "def conv_block_2nd(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_2nd(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def slice_tensor(x, start, stop, axis):\n",
    "    if axis == 3:\n",
    "        return x[:, :, :, start:stop]\n",
    "    elif axis == 1:\n",
    "        return x[:, start:stop, :, :]\n",
    "    else:\n",
    "        raise ValueError(\"Slice axis should be in (1, 3), got {}.\".format(axis))\n",
    "\n",
    "def GroupConv2D(filters,\n",
    "                kernel_size,\n",
    "                strides=(1, 1),\n",
    "                groups=32,\n",
    "                kernel_initializer='he_uniform',\n",
    "                use_bias=True,\n",
    "                activation='linear',\n",
    "                padding='valid',\n",
    "                **kwargs):\n",
    "    \"\"\"\n",
    "    Grouped Convolution Layer implemented as a Slice,\n",
    "    Conv2D and Concatenate layers. Split filters to groups, apply Conv2D and concatenate back.\n",
    "    Args:\n",
    "        filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number of output filters in the convolution).\n",
    "        kernel_size: An integer or tuple/list of a single integer,\n",
    "            specifying the length of the 1D convolution window.\n",
    "        strides: An integer or tuple/list of a single integer, specifying the stride\n",
    "            length of the convolution.\n",
    "        groups: Integer, number of groups to split input filters to.\n",
    "        kernel_initializer: Regularizer function applied to the kernel weights matrix.\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        activation: Activation function to use (see activations).\n",
    "            If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "        padding: one of \"valid\" or \"same\" (case-insensitive).\n",
    "    Input shape:\n",
    "        4D tensor with shape: (batch, rows, cols, channels) if data_format is \"channels_last\".\n",
    "    Output shape:\n",
    "        4D tensor with shape: (batch, new_rows, new_cols, filters) if data_format is \"channels_last\".\n",
    "        rows and cols values might have changed due to padding.\n",
    "    \"\"\"\n",
    "\n",
    "    slice_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        inp_ch = int(backend.int_shape(input_tensor)[-1] // groups)  # input grouped channels\n",
    "        out_ch = int(filters // groups)  # output grouped channels\n",
    "\n",
    "        blocks = []\n",
    "        for c in range(groups):\n",
    "            slice_arguments = {\n",
    "                'start': c * inp_ch,\n",
    "                'stop': (c + 1) * inp_ch,\n",
    "                'axis': slice_axis,\n",
    "            }\n",
    "            x = Lambda(slice_tensor, arguments=slice_arguments)(input_tensor)\n",
    "            x = Conv2D(out_ch,\n",
    "                              kernel_size,\n",
    "                              strides=strides,\n",
    "                              kernel_initializer=kernel_initializer,\n",
    "                              use_bias=use_bias,\n",
    "                              activation=activation,\n",
    "                              padding=padding)(x)\n",
    "            blocks.append(x)\n",
    "\n",
    "        x = Concatenate(axis=slice_axis)(blocks)\n",
    "        return x\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fad668-ac37-4540-9e5e-7a57328be6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNeXt(\n",
    "        model_params,\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        classes=1000,\n",
    "        weights='imagenet',\n",
    "        **kwargs):\n",
    "    \"\"\"Instantiates the ResNet, SEResNet architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    Args:\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    Returns:\n",
    "        A Keras model instance.\n",
    "    Raises:\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape, name='data')\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # get parameters for model layers\n",
    "    no_scale_bn_params = get_bn_params(scale=False)\n",
    "    bn_params = get_bn_params()\n",
    "    conv_params = get_conv_params()\n",
    "\n",
    "    # resnext bottom\n",
    "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
    "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
    "    x = Activation('relu', name='relu0')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
    "\n",
    "    # resnext body\n",
    "    init_filters = 128\n",
    "    for stage, rep in enumerate(model_params.repetitions):\n",
    "        for block in range(rep):\n",
    "\n",
    "            filters = init_filters * (2 ** stage)\n",
    "\n",
    "            # first block of first stage without strides because we have maxpooling before\n",
    "            if stage == 0 and block == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(1, 1), **kwargs)(x)\n",
    "\n",
    "            elif block == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(2, 2), **kwargs)(x)\n",
    "\n",
    "            else:\n",
    "                x = identity_block(filters, stage, block, **kwargs)(x)\n",
    "\n",
    "    # resnext top\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
    "        x = Dense(classes, name='fc1')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    if weights:\n",
    "        if type(weights) == str and os.path.exists(weights):\n",
    "            model.load_weights(weights)\n",
    "        else:\n",
    "            load_model_weights(model, model_params.model_name,\n",
    "                               weights, classes, include_top, **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a5cbe-d2fc-4ea6-b709-0dea6e03c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChannelSE(reduction=16, **kwargs):\n",
    "    \"\"\"\n",
    "    Squeeze and Excitation block, reimplementation inspired by\n",
    "        https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/senet.py\n",
    "    Args:\n",
    "        reduction: channels squeeze factor\n",
    "    \"\"\"\n",
    "    channels_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        # get number of channels/filters\n",
    "        channels = backend.int_shape(input_tensor)[channels_axis]\n",
    "\n",
    "        x = input_tensor\n",
    "\n",
    "        # squeeze and excitation block in PyTorch style with\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Lambda(expand_dims, arguments={'channels_axis': channels_axis})(x)\n",
    "        x = Conv2D(channels // reduction, (1, 1), kernel_initializer='he_uniform')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(channels, (1, 1), kernel_initializer='he_uniform')(x)\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "        # apply attention\n",
    "        x = Multiply()([input_tensor, x])\n",
    "\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "def SEResNeXtBottleneck(filters, reduction=16, strides=1, groups=32, base_width=4, **kwargs):\n",
    "    bn_params = get_bn_params()\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        x = input_tensor\n",
    "        residual = input_tensor\n",
    "\n",
    "        width = (filters // 4) * base_width * groups // 64\n",
    "\n",
    "        # bottleneck\n",
    "        x = Conv2D(width, (1, 1), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = ZeroPadding2D(1)(x)\n",
    "        x = GroupConv2D(width, (3, 3), strides=strides, groups=groups,\n",
    "                        kernel_initializer='he_uniform', use_bias=False, **kwargs)(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(filters, (1, 1), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "\n",
    "        #  if number of filters or spatial dimensions changed\n",
    "        #  make same manipulations with residual connection\n",
    "        x_channels = get_num_channels(x)\n",
    "        r_channels = get_num_channels(residual)\n",
    "\n",
    "        if strides != 1 or x_channels != r_channels:\n",
    "            residual = Conv2D(x_channels, (1, 1), strides=strides,\n",
    "                                     kernel_initializer='he_uniform', use_bias=False)(residual)\n",
    "            residual = BatchNormalization(**bn_params)(residual)\n",
    "\n",
    "        # apply attention module\n",
    "        x = ChannelSE(reduction=reduction, **kwargs)(x)\n",
    "\n",
    "        # add residual connection\n",
    "        x = Add()([x, residual])\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e429a-91a6-43de-9d43-1d21fabd2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEResNext50(\n",
    "        model_params,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        include_top=True,\n",
    "        classes=1000,\n",
    "        weights='imagenet',\n",
    "        **kwargs\n",
    "):\n",
    "    \"\"\"Instantiates the ResNet, SEResNet architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    Args:\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    Returns:\n",
    "        A Keras model instance.\n",
    "    Raises:\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    residual_block = model_params.residual_block\n",
    "    init_filters = model_params.init_filters\n",
    "    bn_params = get_bn_params()\n",
    "\n",
    "    # define input\n",
    "    if input_tensor is None:\n",
    "        input = Input(shape=input_shape, name='input')\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            input = input_tensor\n",
    "\n",
    "    x = input\n",
    "\n",
    "    if model_params.input_3x3:\n",
    "\n",
    "        x = ZeroPadding2D(1)(x)\n",
    "        x = Conv2D(init_filters, (3, 3), strides=2,\n",
    "                          use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = ZeroPadding2D(1)(x)\n",
    "        x = Conv2D(init_filters, (3, 3), use_bias=False,\n",
    "                          kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = ZeroPadding2D(1)(x)\n",
    "        x = Conv2D(init_filters * 2, (3, 3), use_bias=False,\n",
    "                          kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    else:\n",
    "        x = ZeroPadding2D(3)(x)\n",
    "        x = Conv2D(init_filters, (7, 7), strides=2, use_bias=False,\n",
    "                          kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization(**bn_params)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(1)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2)(x)\n",
    "\n",
    "    # body of resnet\n",
    "    filters = model_params.init_filters * 2\n",
    "    for i, stage in enumerate(model_params.repetitions):\n",
    "\n",
    "        # increase number of filters with each stage\n",
    "        filters *= 2\n",
    "\n",
    "        for j in range(stage):\n",
    "\n",
    "            # decrease spatial dimensions for each stage (except first, because we have maxpool before)\n",
    "            if i == 0 and j == 0:\n",
    "                x = residual_block(filters, reduction=model_params.reduction,\n",
    "                                   strides=1, groups=model_params.groups, is_first=True, **kwargs)(x)\n",
    "\n",
    "            elif i != 0 and j == 0:\n",
    "                x = residual_block(filters, reduction=model_params.reduction,\n",
    "                                   strides=2, groups=model_params.groups, **kwargs)(x)\n",
    "            else:\n",
    "                x = residual_block(filters, reduction=model_params.reduction,\n",
    "                                   strides=1, groups=model_params.groups, **kwargs)(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        if model_params.dropout is not None:\n",
    "            x = Dropout(model_params.dropout)(x)\n",
    "        x = Dense(classes)(x)\n",
    "        x = Activation('softmax', name='output')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = input\n",
    "\n",
    "    model = Model(inputs, x, name=\"SEResNext50\")\n",
    "\n",
    "    if weights:\n",
    "        if type(weights) == str and os.path.exists(weights):\n",
    "            model.load_weights(weights)\n",
    "        else:\n",
    "            load_model_weights(model, model_params.model_name,\n",
    "                               weights, classes, include_top, **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5930a44-2c34-4ee4-9045-8c7b7ab8fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_seresnext50_unet(input_shape):\n",
    "    inputs = Input(input_shape, name=\"input_1\")\n",
    "    \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
    "    MODEL_PARS = ModelParams(\n",
    "        'seresnext50', repetitions=(3, 4, 6, 3), residual_block=SEResNeXtBottleneck,\n",
    "        groups=32, reduction=16, init_filters=64, input_3x3=False, dropout=None,\n",
    "    )\n",
    "    seresnext50 = SEResNext50(MODEL_PARS, weights=None, input_tensor=inputs)\n",
    "    \n",
    "    # seresnext50.summary()\n",
    "    # for idx, layer in enumerate(seresnext50.layers):\n",
    "    #     print(idx, layer.name, layer.output.type_spec.shape)\n",
    "        \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = seresnext50.get_layer(index=0).output           ## (512 x 512)\n",
    "    s2 = seresnext50.get_layer(index=4).output        ## (256 x 256)\n",
    "    s3 = seresnext50.get_layer(index=257).output  ## (128 x 128)\n",
    "    s4 = seresnext50.get_layer(index=587).output  ## (64 x 64)\n",
    "    s5 = seresnext50.get_layer(index=1081).output  ## (32 x 32)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = seresnext50.get_layer(index=1326).output  ## (16 x 16)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    x = IMG_SIZE\n",
    "    d1 = decoder_block(b1, s5, x)                     ## (32 x 32)\n",
    "    x = x/2\n",
    "    d2 = decoder_block(d1, s4, x)                     ## (64 x 64)\n",
    "    x = x/2\n",
    "    d3 = decoder_block(d2, s3, x)                     ## (128 x 128)\n",
    "    x = x/2\n",
    "    d4 = decoder_block(d3, s2, x)                      ## (256 x 256)\n",
    "    x = x/2\n",
    "    d5 = decoder_block(d4, s1, x)                      ## (512 x 512)\n",
    "\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"SEResNext50_U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0d1d8-50f5-4ddc-83d5-30efddd992f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "    model = build_seresnext50_unet(input_shape)\n",
    "    # model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
